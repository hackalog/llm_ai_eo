<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Bokeh Plot</title>
    <style>
      html, body {
        box-sizing: border-box;
        display: flow-root;
        height: 100%;
        margin: 0;
        padding: 0;
      }
    </style>
    <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js"></script>
    <script type="text/javascript">
        Bokeh.set_log_level("info");
    </script>
  </head>
  <body>
    <div id="e9ebadd3-045d-4e2c-9b5e-a91173f9af64" data-root-id="p1276" style="display: contents;"></div>
  
    <script type="application/json" id="p1322">
      {"a482eea9-0ced-4ca4-9567-4517c36bf689":{"version":"3.3.0","title":"Bokeh Application","roots":[{"type":"object","name":"Figure","id":"p1276","attributes":{"width":800,"height":800,"x_range":{"type":"object","name":"DataRange1d","id":"p1277"},"y_range":{"type":"object","name":"DataRange1d","id":"p1278"},"x_scale":{"type":"object","name":"LinearScale","id":"p1285"},"y_scale":{"type":"object","name":"LinearScale","id":"p1286"},"title":{"type":"object","name":"Title","id":"p1283"},"renderers":[{"type":"object","name":"GlyphRenderer","id":"p1311","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p1273","attributes":{"selected":{"type":"object","name":"Selection","id":"p1274","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p1275"},"data":{"type":"map","entries":[["index",{"type":"ndarray","array":{"type":"bytes","data":"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"},"shape":[742],"dtype":"int32","order":"little"}],["x",{"type":"ndarray","array":{"type":"bytes","data":"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"},"shape":[742],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"WMbbQASmikAJhgxBkahrQP0ca0BwIodA2BtxQK/WZ0A37GJAHettQJ+GaUDEYmxAKdVnQF09XUD7TLhAUU/kQAUgAUHrUgJBRMrzQE2uAEF4wOhAcCP5QFnDyUC84+BAL0HTQMjuBkFfnc9AHVfjQDXU20DLtwFB2SbiQBHYAkHRAO9A1En/QBwJAEHjA+tA3zUBQfbC6kDcV/1AZeoEQZDH5EBlKfZAQYjkQGnk30A6cdRALknZQBiN4kCas+tAFO7wQCKI+kD24utAy6D6QA4K20C7u6tAa4beQF4r3kAZbetAuordQPoP8UD+UwhBNXa6QIbZpEC4o59AqtkIQWdpBkGY8AlBCu3+QGOu60C938NAm+cDQZx5AEG+YPdAxMUBQUeQA0H+qABBEtQBQSUgBEFYmQRBcf8FQZFnA0EIvwFB/QYDQQvFAkHQBQdBd+UFQS+VAkFUdABBVw/jQGbF8kDCXKdA9KKiQAVypUCRyLZAtmOnQHsey0Co1bhAromjQJa5q0DOquJAMV6qQNBF2EAg/tJAasOzQKq94UD06NdA9AXgQHB50UDb/eNAYcPEQKlm2ECCD9lAKf7CQOKO2kB+0MpAfbfDQANeyUBwiclAd5m6QMoOzUB2xsdAd5/aQDiZtUD4I7RAn/7iQHhduUAStdpAlhbgQNDi2kAi/ulAXYrVQKIm2EAYpLxAATy2QGehv0BDhAtBcEoLQc3/CkFGXwlBP/YKQZnfCEF3W4BAmpeuQG9EtUAZGKdAfH/HQMDFvkBkzc1AIFmEQNjwmUDJqJZA7qyjQCEcnED5m6JAbMiRQAYepUCG25ZACmuSQNfrpkAvg5hAFKicQB2kgEBwOKZAwFSnQB3+nkBzJpVA3laYQF4slUB8PIhA4ISCQPNkmUCyxqJAqZeYQIxgmEA3m5RAEp2lQBu6wUCMD8JAz/TLQBwDvUBwrrtAEG2VQPnXpECSN6ZA+BSnQMxzj0BpDodALkWaQBnduED3nsVARdYHQdXS0UDEvdFA/HS+QOMti0Cv4oNAuJKLQEt0kEBEnZNA+geLQB3bh0DNM9NAj6idQG2syUAqRI1AohiIQHZXg0AI+YdADN+KQJlShkAN8YJAckSFQCIrV0AiKIVA6BaNQDJLkkD12rdA0/SNQOB+rUD59rBAc92rQK0/tkBqmYpAQjyKQFV4wEA5JJ9A+YCYQK/ckkAfcKdARd2hQAI+jkBPRMpAJq3JQLgTy0BOcs5ASx/PQEdL7kChis1AWlvSQMdSt0CAiLBAiuevQGtWtUBPkqtATgyJQGgTmUA27JJAaiiLQEXVo0C4Q41ANUWOQKSdoEAUbqBAfnapQB6yqEDgy6RAgcGnQONkikDzx5NA6zCsQNkaq0DcmZRAg5egQBlhlkBky7tAogWFQImwv0CXY5FAiv62QNzHtUCJ+L1AeSqyQOzqxUBAOsBA56m0QDfzuEBBBpFA6ZWTQIRgtUBG0bNAzTCVQMeuvUCisclAdPbAQEiUlUCAcslAWd+vQGd9qkBPD99Ab6+/QDK0m0CxrqxAhaWpQAf8qEAg+J5A0+SUQNQDl0CfbLpAfK3FQF7ov0Co0dlAMc+0QN83hUDmTtBAahXIQFxPnUBt77pAYm6rQPQ6vECyJbJAv8uwQLaRt0CZesZA+LBwQJE6gUA4QXtAPXzeQLPxfEAdO7BAHWW4QCyKvkBQvaJAik24QK516kAEmuxA+CviQKbNwkDZGc5ALlrUQFNTwEB0IsVALsjWQE2vwkCdGXtARsu+QH3suUArfXhA4NuAQDznyEC/zXlAS4WHQM7Db0ABTX5AGeR5QFkutUDSR2xA2EBfQAuihEBZzKdAP3VYQNJLtkBuGl5AzPxYQMDpVkCVdIFADChgQMTSbkCPDWhARU9qQPypYECzKGtAW9jWQBvBVkCs21pAUI94QCu2jUC2Haw/JOOjQNqCskCMLaNAko22QE1WskAoB6hAhZbGQGBb0EBmbbRAZFKLQNZ41kCZFtBAfHXbQGVv4kAExqJA74XPQMEujkCQ/LFAGdWvQMwl10D72LdAX7OqQCLXpkASCqhA659fQDM+P0CgjklAW+Ckvr13RL4YjGG+uESlvhPLgL7AdJS+mQcUvlr5Ob6+BpA8ZpGYvhEwUr5kDSW+wL7OvXl74j1T0qQ+29rMPhXPpz4D2fk97IipPiw2Mj5DlkQ/n5EwP+7sOD+NT2I/IelFP4oRLD8cauM+8HbLPgGIQEDwvUhAaKiVQDNyuz+hiLY/KRGUQHcok0BTlK9AxoKwQECRgkDHBL1A5HXPQJ7I5UBBfntApx3kQJ8yhUCRj9hAsrN+QK3q2ECzknhA7hrjQIvRNUCgVdNAxo/gQLAcaEAhE9FAM9/mQPcBckCjT8tAklLhQE8IjkA2wt9AgXLJQD9l10AIf6ZAxsXWQCbesUBG9NVAmNKjQAdc0EBZA+pAuWuMQGoH6UAC5o1Av6bQQDuVlUCClcFARfnOQHurgUC0685AjgetQFbP10AOBatAW6zNQNK3aUB+t9RA4ljFQF520EBFFp5A47/PQLnZUUAEnMZAGHTZQM0hqEAeMsxAHifPQLbkcUClodFAwVbCQHvD1UDfXqxAvvPSQHMqc0ClNttAkuhIQLGlykC8ltFA1atkQEmXykAlMsZAbk7QQK/5RUD05NBAzvnBQL1ZxkCaGtZAj8iDQIhe1ED+ucRAbY/UQJFZnkCQ99dAJ/2ZQH+mxEAbitdA4Ul2QPLUxEBd4XlA9abDQGLB3UAuwJpAv3S2QOtb3EBCSKJAeem8QOLv3UDOxZ9ADSvCQNLl4EDrCn5Aqu3KQG/P4ECWP35AbgnTQFtP1kDqoZ1Arye9QKNg0EDu3aFAqvTNQAuNoUAO7dRAX+rPQNRXqEA9xdhAc1HfQNQtekCvjc9AzlnvQMK5VEA2W+1AUkhhQLFRSkCaxjVALfLyQLIQp0CbC/ZAeP63QBSA8UDFkaVAzODLQBil70C1UWFA/abmQOe6ikBlTi9Aqu4jQKGOLUBVyiJAUZMpQDkWJUBevi9A8xD1QHS7X0CgOMRACDPyQCMu2EDp/D9AnIY8QPqWOUAEvztAgzdAQD5cPkAurvFAsq7bQI8OVkDs/1xAoyFaQIAoW0CC9llAWM9NQBFLXkCntM5ASmj2QDwLU0D2KvVAMmtdQKNi1EAhhb1At4KEQBBIvEAkPZ1AYaDLQHiJAUFsA8FAee3/QL9zuEDeRapAHmrJQFDqBEHJhMtAcYjnQDLKzEDEosZA2jvDQGJGpUChNqVAX2inQIl3pUAiidBAdTPKQFEGwkAA6YhAwUCZQG83kEAbkJxAVaaRQKfclUCwbJRADCygQLYQ4EBM6PFAEvf4QA7xv0BKVPtAQ8O0QKrK30DW4f9AFGb7QPmlBkGtzAVBHNwBQbEr+kCcR/JAyUr4QJVX+UCt4/tAdOLyQMVCCEGDxAZBExcHQa6FBUHRUAhBJsf+QCZIBUFOGuJAYrICQQZc5kBhp+dAzr++QJKlBkF63QVBOo0JQbHe9UBkuOpAs37oQHqVAUHlqfVAFH/0QIft/kDKPPVAoMbsQGeF/EDpn/9Agu74QML2+UAR+uhAAIkDQRm2AEGs9v1A75zrQHE79kBje/ZATAfoQELGA0F6JAVBF1/7QB2P5kDLKPJACsgGQRPT20Dx4/ZAa2viQGco+UAl8fRAafP+QM4O+UD5bNpA1dsMQWskDEG84wtBHgsMQWWdDkFS2Q1BaDMJQZg5DkHeCgpBUUAMQbb3DkGMnA5BtFQyQOs9MEBiBD9ArRtBQMruLEDpFjNA8Rs7QM5dMkASnjJAkKExQBhIMUDnqzRAFPg/QLAzN0C1nypAkcEtQCgFQ0CHsy5AcLw1QOvUPUCWuTpAPwcqQJiJNkC83itAHLBHQHrRQUCPoj5AU79EQO18Q0DRnlBA4gm+QA=="},"shape":[742],"dtype":"float32","order":"little"}],["label",{"type":"ndarray","array":["us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","us-eo-lines.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","tbs-automated-decisions.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","g7-coc.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt","bletchley-declaration.txt"],"shape":[742],"dtype":"object","order":"little"}],["color",{"type":"ndarray","array":["#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#5e4fa2","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#bfe5a0","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#fdbf6f","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142","#9e0142"],"shape":[742],"dtype":"object","order":"little"}],["text",{"type":"ndarray","array":["passage: # Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence","passage: By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows:","passage: Section 1.\u00a0 Purpose.\u00a0 Artificial intelligence (AI) holds extraordinary potential for both promise and peril.\u00a0 Responsible AI use has the potential to help solve urgent challenges while making our world more prosperous, productive, innovative, and secure.\u00a0 At the same time, irresponsible use could exacerbate societal harms such as fraud, discrimination, bias, and disinformation; displace and disempower workers; stifle competition; and pose risks to national security.\u00a0 Harnessing AI for good and realizing its myriad benefits requires mitigating its substantial risks.\u00a0 This endeavor demands a society-wide effort that includes government, the private sector, academia, and civil society.","passage: My Administration places the highest urgency on governing the development and use of AI safely and responsibly, and is therefore advancing a coordinated, Federal Government-wide approach to doing so.\u00a0The rapid speed at which AI capabilities are advancing compels the United States to lead in this moment for the sake of our security, economy, and society.","passage: In the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built.\u00a0 I firmly believe that the power of our ideals; the foundations of our society; and the creativity, diversity, and decency of our people are the reasons that America thrived in past eras of rapid change.\u00a0 They are the reasons we will succeed again in this moment.\u00a0 We are more than capable of harnessing AI for justice, security, and opportunity for all.","passage: Sec.2.\u00a0 Policy and Principles.\u00a0 It is the policy of my Administration to advance and govern the development and use of AI in accordance with eight guiding principles and priorities.\u00a0 When undertaking the actions set forth in this order, executive departments and agencies (agencies) shall, as appropriate and consistent with applicable law, adhere to these principles, while, as feasible, taking into account the views of other agencies, industry, members of academia, civil society, labor unions, international allies and partners, and other relevant organizations:","passage: (a)\u00a0 Artificial Intelligence must be safe and secure.\u00a0 Meeting this goal requires robust, reliable, repeatable, and standardized evaluations of AI systems, as well as policies, institutions, and, as appropriate, other mechanisms to test, understand, and mitigate risks from these systems before they are put to use.\u00a0 It also requires addressing AI systems\u2019 most pressing security risks \u2014 including with respect to biotechnology, cybersecurity, critical infrastructure, and other national security dangers \u2014 while navigating AI\u2019s opacity and complexity.\u00a0 Testing and evaluations, including post-deployment performance monitoring, will help ensure that AI systems function as intended, are resilient against misuse or dangerous modifications, are ethically developed and operated in a secure manner, and are compliant with applicable Federal laws and policies.\u00a0 Finally, my Administration will help develop effective labeling and content provenance mechanisms, so that Americans are able to determine when content is generated using AI and when it is not.\u00a0 These actions will provide a vital foundation for an approach that addresses AI\u2019s risks without unduly reducing its benefits.","passage: (b)\u00a0 Promoting responsible innovation, competition, and collaboration will allow the United States to lead in AI and unlock the technology\u2019s potential to solve some of society\u2019s most difficult challenges.\u00a0 This effort requires investments in AI-related education, training, development, research, and capacity, while simultaneously tackling novel intellectual property (IP) questions and other problems to protect inventors and creators.\u00a0 Across the Federal Government, my Administration will support programs to provide Americans the skills they need for the age of AI and attract the world\u2019s AI talent to our shores \u2014 not just to study, but to stay \u2014 so that the companies and technologies of the future are made in America.\u00a0 The Federal Government will promote a fair, open, and competitive ecosystem and marketplace for AI and related technologies so that small developers and entrepreneurs can continue to drive innovation.\u00a0 Doing so requires stopping unlawful collusion and addressing risks from dominant firms\u2019 use of key assets such as semiconductors, computing power, cloud storage, and data to disadvantage competitors, and it requires supporting a marketplace that harnesses the benefits of AI to provide new opportunities for small businesses, workers, and entrepreneurs.","passage: (c)\u00a0 The responsible development and use of AI require a commitment to supporting American workers.\u00a0 As AI creates new jobs and industries, all workers need a seat at the table, including through collective bargaining, to ensure that they benefit from these opportunities.\u00a0 My Administration will seek to adapt job training and education to support a diverse workforce and help provide access to opportunities that AI creates.\u00a0 In the workplace itself, AI should not be deployed in ways that undermine rights, worsen job quality, encourage undue worker surveillance, lessen market competition, introduce new health and safety risks, or cause harmful labor-force disruptions.\u00a0 The critical next steps in AI development should be built on the views of workers, labor unions, educators, and employers to support responsible uses of AI that improve workers\u2019 lives, positively augment human work, and help all people safely enjoy the gains and opportunities from technological innovation.","passage: (d)\u00a0 Artificial Intelligence policies must be consistent with my Administration\u2019s dedication to advancing equity and civil rights.\u00a0 My Administration cannot \u2014 and will not \u2014 tolerate the use of AI to disadvantage those who are already too often denied equal opportunity and justice.\u00a0 From hiring to housing to healthcare, we have seen what happens when AI use deepens discrimination and bias, rather than improving quality of life.\u00a0 Artificial Intelligence systems deployed irresponsibly have reproduced and intensified existing inequities, caused new types of harmful discrimination, and exacerbated online and physical harms.\u00a0 My Administration will build on the important steps that have already been taken \u2014 such as issuing the Blueprint for an AI Bill of Rights, the AI Risk Management Framework, and Executive Order 14091 of February 16, 2023 (Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government) \u2014 in seeking to ensure that AI complies with all Federal laws and to promote robust technical evaluations, careful oversight, engagement with affected communities, and rigorous regulation.\u00a0 It is necessary to hold those developing and deploying AI accountable to standards that protect against unlawful discrimination and abuse, including in the justice system and the Federal Government.\u00a0 Only then can Americans trust AI to advance civil rights, civil liberties, equity, and justice for all.","passage: (e)\u00a0 The interests of Americans who increasingly use, interact with, or purchase AI and AI-enabled products in their daily lives must be protected.\u00a0 Use of new technologies, such as AI, does not excuse organizations from their legal obligations, and hard-won consumer protections are more important than ever in moments of technological change.\u00a0 The Federal Government will enforce existing consumer protection laws and principles and enact appropriate safeguards against fraud, unintended bias, discrimination, infringements on privacy, and other harms from AI.\u00a0 Such protections are especially important in critical fields like healthcare, financial services, education, housing, law, and transportation, where mistakes by or misuse of AI could harm patients, cost consumers or small businesses, or jeopardize safety or rights.\u00a0 At the same time, my Administration will promote responsible uses of AI that protect consumers, raise the quality of goods and services, lower their prices, or expand selection and availability.","passage: (f)\u00a0 Americans\u2019 privacy and civil liberties must be protected as AI continues advancing.\u00a0 Artificial Intelligence is making it easier to extract, re-identify, link, infer, and act on sensitive information about people\u2019s identities, locations, habits, and desires.\u00a0 Artificial Intelligence\u2019s capabilities in these areas can increase the risk that personal data could be exploited and exposed.\u00a0 To combat this risk, the Federal Government will ensure that the collection, use, and retention of data is lawful, is secure, and mitigates privacy and confidentiality risks.\u00a0 Agencies shall use available policy and technical tools, including privacy-enhancing technologies (PETs) where appropriate, to protect privacy and to combat the broader legal and societal risks \u2014 including the chilling of First Amendment rights \u2014 that result from the improper collection and use of people\u2019s data.","passage: (g)\u00a0 It is important to manage the risks from the Federal Government\u2019s own use of AI and increase its internal capacity to regulate, govern, and support responsible use of AI to deliver better results for Americans.\u00a0 These efforts start with people, our Nation\u2019s greatest asset.\u00a0 My Administration will take steps to attract, retain, and develop public service-oriented AI professionals, including from underserved communities, across\u00a0disciplines \u2014 including technology, policy, managerial,\u00a0procurement, regulatory, ethical, governance, and legal fields \u2014 and ease AI professionals\u2019 path into the Federal Government to help harness and govern AI.\u00a0 The Federal Government will work to ensure that all members of its workforce receive adequate training to understand the benefits, risks, and limitations of AI for their job functions, and to modernize Federal Government information technology infrastructure, remove\u00a0bureaucratic obstacles, and ensure that safe and rights-respecting AI is adopted, deployed, and used.","passage: (h)\u00a0 The Federal Government should lead the way to global societal, economic, and technological progress, as the United\u00a0States has in previous eras of disruptive innovation and change.\u00a0 This leadership is not measured solely by the technological advancements our country makes.\u00a0 Effective leadership also means pioneering those systems and safeguards needed to deploy technology responsibly \u2014 and building and promoting those safeguards with the rest of the world.\u00a0My Administration will engage with international allies and partners in developing a framework to manage AI\u2019s risks, unlock AI\u2019s potential for good, and promote common approaches to shared challenges.\u00a0 The Federal Government will seek to promote responsible AI safety and security principles and actions with other nations, including our competitors, while leading key global conversations and collaborations to ensure that AI benefits the whole world, rather than exacerbating inequities, threatening human rights, and causing other harms.","passage: Sec.3.\u00a0 Definitions.\u00a0 For purposes of this order:","passage: (a)\u00a0 The term \u201cagency\u201d means each agency described in 44\u00a0U.S.C. 3502(1), except for the independent regulatory agencies described in 44 U.S.C. 3502(5).","passage: (b)\u00a0 The term \u201cartificial intelligence\u201d or \u201cAI\u201d has the meaning set forth in 15 U.S.C. 9401(3): \u00a0a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments.\u00a0 Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.","passage: (c)\u00a0 The term \u201cAI model\u201d means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.","passage: (d)\u00a0 The term \u201cAI red-teaming\u201d means a structured testing effort to find flaws and vulnerabilities in an AI system, often in a controlled environment and in collaboration with developers of AI.\u00a0 Artificial Intelligence red-teaming is most often performed by dedicated \u201cred teams\u201d that adopt adversarial methods to identify flaws and vulnerabilities, such as harmful or discriminatory outputs from an AI system, unforeseen or undesirable system behaviors, limitations, or potential risks associated with the misuse of the system.","passage: (e)\u00a0 The term \u201cAI system\u201d means any data system, software, hardware, application, tool, or utility that operates in whole or in part using AI.","passage: (f)\u00a0 The term \u201ccommercially available information\u201d means any information or data about an individual or group of individuals, including an individual\u2019s or group of individuals\u2019 device or location, that is made available or obtainable and sold, leased, or licensed to the general public or to governmental or non-governmental entities.","passage: (g)\u00a0 The term \u201ccrime forecasting\u201d means the use of analytical techniques to attempt to predict future crimes or crime-related information.\u00a0 It can include machine-generated predictions that use algorithms to analyze large volumes of data, as well as other forecasts that are generated without machines and based on statistics, such as historical crime statistics.","passage: (h)\u00a0 The term \u201ccritical and emerging technologies\u201d means those technologies listed in the February 2022 Critical and Emerging Technologies List Update issued by the National Science and Technology Council (NSTC), as amended by subsequent updates to the list issued by the NSTC.","passage: (i)\u00a0 The term \u201ccritical infrastructure\u201d has the meaning set forth in section 1016(e) of the USA PATRIOT Act of 2001, 42\u00a0U.S.C. 5195c(e).","passage: (j)\u00a0 The term \u201cdifferential-privacy guarantee\u201d means protections that allow information about a group to be shared while provably limiting the improper access, use, or disclosure of personal information about particular entities.","passage: (k)\u00a0 The term \u201cdual-use foundation model\u201d means an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts; and that exhibits, or could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters, such as by:","passage: (i) \u00a0\u00a0\u00a0substantially lowering the barrier of entry for non-experts to design, synthesize, acquire, or use chemical, biological, radiological, or nuclear (CBRN) weapons;","passage: (ii)\u00a0 \u00a0enabling powerful offensive cyber operations through automated vulnerability discovery and exploitation against a wide range of potential targets of cyber attacks; or","passage: (iii)\u00a0 permitting the evasion of human control or oversight through means of deception or obfuscation.","passage: Models meet this definition even if they are provided to end users with technical safeguards that attempt to prevent users from taking advantage of the relevant unsafe capabilities.","passage: (l)\u00a0 The term \u201cFederal law enforcement agency\u201d has the meaning set forth in section 21(a) of Executive Order 14074 of May 25, 2022 (Advancing Effective, Accountable Policing and Criminal Justice Practices To Enhance Public Trust and Public Safety).","passage: (m)\u00a0 The term \u201cfloating-point operation\u201d means any mathematical operation or assignment involving floating-point numbers, which are a subset of the real numbers typically represented on computers by an integer of fixed precision scaled by an integer exponent of a fixed base.","passage: (n)\u00a0 The term \u201cforeign person\u201d has the meaning set forth in section 5(c) of Executive Order 13984 of January 19, 2021 (Taking Additional Steps To Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities).","passage: (o)\u00a0 The terms \u201cforeign reseller\u201d and \u201cforeign reseller of United States Infrastructure as a Service Products\u201d mean a foreign person who has established an Infrastructure as a Service Account to provide Infrastructure as a Service Products subsequently, in whole or in part, to a third party.","passage: (p)\u00a0 The term \u201cgenerative AI\u201d means the class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content.\u00a0 This can include images, videos, audio, text, and other digital content.","passage: (q)\u00a0 The terms \u201cInfrastructure as a Service Product,\u201d \u201cUnited States Infrastructure as a Service Product,\u201d \u201cUnited States Infrastructure as a Service Provider,\u201d and \u201cInfrastructure as a Service Account\u201d each have the respective meanings given to those terms in section 5 of Executive Order 13984.","passage: (r)\u00a0 The term \u201cinteger operation\u201d means any mathematical operation or assignment involving only integers, or whole numbers expressed without a decimal point.","passage: (s)\u00a0 The term \u201cIntelligence Community\u201d has the meaning given to that term in section 3.5(h) of Executive Order 12333 of December 4, 1981 (United States Intelligence Activities), as amended.","passage: (t)\u00a0 The term \u201cmachine learning\u201d means a set of techniques that can be used to train AI algorithms to improve performance at a task based on data.","passage: (u)\u00a0 The term \u201cmodel weight\u201d means a numerical parameter within an AI model that helps determine the model\u2019s outputs in response to inputs.","passage: (v)\u00a0 The term \u201cnational security system\u201d has the meaning set forth in 44 U.S.C. 3552(b)(6).","passage: (w)\u00a0 The term \u201comics\u201d means biomolecules, including nucleic acids, proteins, and metabolites, that make up a cell or cellular system.","passage: (x)\u00a0 The term \u201cOpen RAN\u201d means the Open Radio Access Network approach to telecommunications-network standardization adopted by the O-RAN Alliance, Third Generation Partnership Project, or any similar set of published open standards for multi-vendor network equipment interoperability.","passage: (y)\u00a0 The term \u201cpersonally identifiable information\u201d has the meaning set forth in Office of Management and Budget (OMB) Circular No.A-130.","passage: (z)\u00a0 The term \u201cprivacy-enhancing technology\u201d means any software or hardware solution, technical process, technique, or other technological means of mitigating privacy risks arising from data processing, including by enhancing predictability, manageability, disassociability, storage, security, and confidentiality.\u00a0 These technological means may include secure multiparty computation, homomorphic encryption, zero-knowledge proofs, federated learning, secure enclaves, differential privacy, and synthetic-data-generation tools.\u00a0 This is also sometimes referred to as \u201cprivacy-preserving technology.\u201d","passage: (aa)\u00a0 The term \u201cprivacy impact assessment\u201d has the meaning set forth in OMB Circular No.A-130.","passage: (bb)\u00a0 The term \u201cSector Risk Management Agency\u201d has the meaning set forth in 6 U.S.C. 650(23).","passage: (cc)\u00a0 The term \u201cself-healing network\u201d means a telecommunications network that automatically diagnoses and addresses network issues to permit self-restoration.","passage: (dd)\u00a0 The term \u201csynthetic biology\u201d means a field of science that involves redesigning organisms, or the biomolecules of organisms, at the genetic level to give them new characteristics.\u00a0 Synthetic nucleic acids are a type of biomolecule redesigned through synthetic-biology methods.","passage: (ee)\u00a0 The term \u201csynthetic content\u201d means information, such as images, videos, audio clips, and text, that has been significantly modified or generated by algorithms, including by AI.","passage: (ff)\u00a0 The term \u201ctestbed\u201d means a facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and technologies, including AI and PETs, to help evaluate the functionality, usability, and performance of those tools or technologies.","passage: (gg)\u00a0 The term \u201cwatermarking\u201d means the act of embedding information, which is typically difficult to remove, into outputs created by AI \u2014 including into outputs such as photos, videos, audio clips, or text \u2014 for the purposes of verifying the authenticity of the output or the identity or characteristics of its provenance, modifications, or conveyance.","passage: Sec.4.\u00a0 Ensuring the Safety and Security of AI Technology.","passage: 4.1.\u00a0 Developing Guidelines, Standards, and Best Practices for AI Safety and Security.\u00a0(a)\u00a0 Within 270 days of the date of this order, to help ensure the development of safe, secure, and trustworthy AI systems, the Secretary of Commerce, acting through the Director of the National Institute of Standards and Technology (NIST), in coordination with the Secretary of Energy, the Secretary of Homeland Security, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall:","passage: (i)\u00a0 \u00a0Establish guidelines and best practices, with the aim of promoting consensus industry standards, for developing and deploying safe, secure, and trustworthy AI systems, including:","passage: (A)\u00a0 developing a companion resource to the AI Risk Management Framework, NIST AI 100-1, for generative AI;","passage: (B)\u00a0 developing a companion resource to the Secure Software Development Framework to incorporate secure development practices for generative AI and for dual-use foundation models; and","passage: (C)\u00a0 launching an initiative to create guidance and benchmarks for evaluating and auditing AI capabilities, with a focus on capabilities through which AI could cause harm, such as in the areas of cybersecurity and biosecurity.","passage: (ii)\u00a0 Establish appropriate guidelines (except for AI used as a component of a national security system), including appropriate procedures and processes, to enable developers of AI, especially of dual-use foundation models, to conduct AI red-teaming tests to enable deployment of safe, secure, and trustworthy systems.\u00a0 These efforts shall include:","passage: (A)\u00a0 coordinating or developing guidelines related to assessing and managing the safety, security, and trustworthiness of dual-use foundation models; and","passage: (B)\u00a0 in coordination with the Secretary of Energy and the Director of the National Science Foundation (NSF), developing and helping to ensure the availability of testing environments, such as testbeds, to support the development of safe, secure, and trustworthy AI technologies, as well as to support the design, development, and deployment of associated PETs, consistent with section 9(b) of this order.","passage: (b)\u00a0 Within 270 days of the date of this order, to understand and mitigate AI security risks, the Secretary of Energy, in coordination with the heads of other Sector Risk Management Agencies (SRMAs) as the Secretary of Energy may deem appropriate, shall develop and, to the extent permitted by law and available appropriations, implement a plan for developing the Department of Energy\u2019s AI model evaluation tools and AI testbeds.\u00a0 The Secretary shall undertake this work using existing solutions where possible, and shall develop these tools and AI testbeds to be capable of assessing near-term extrapolations of AI systems\u2019 capabilities.\u00a0 At a minimum, the Secretary shall develop tools to evaluate AI capabilities to generate outputs that may represent nuclear, nonproliferation, biological, chemical, critical infrastructure, and energy-security threats or hazards.\u00a0 The Secretary shall do this work solely for the purposes of guarding against these threats, and shall also develop model guardrails that reduce such risks.\u00a0 The Secretary shall, as appropriate, consult with private AI laboratories, academia, civil society, and third-party evaluators, and shall use existing solutions.","passage: 4.2.\u00a0 Ensuring Safe and Reliable AI.\u00a0(a)\u00a0 Within 90 days of the date of this order, to ensure and verify the continuous availability of safe, reliable, and effective AI in accordance with the Defense Production Act, as amended, 50 U.S.C. 4501\u00a0_et seq_.,including for the national defense and the protection of critical infrastructure, the Secretary of Commerce shall require:","passage: (i)\u00a0 \u00a0Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records regarding the following:","passage: (A)\u00a0 any ongoing or planned activities related to training, developing, or producing dual-use foundation models, including the physical and cybersecurity protections taken to assure the integrity of that training process against sophisticated threats;","passage: (B)\u00a0 the ownership and possession of the model weights of any dual-use foundation models, and the physical and cybersecurity measures taken to protect those model weights; and","passage: (C)\u00a0 the results of any developed dual-use foundation model\u2019s performance in relevant AI red-team testing based on guidance developed by NIST pursuant to subsection 4.1(a)(ii) of this section, and a description of any associated measures the company has taken to meet safety objectives, such as mitigations to improve performance on these red-team tests and strengthen overall model security.\u00a0Prior to the development of guidance on red-team testing standards by NIST pursuant to subsection 4.1(a)(ii) of this section, this description shall include the results of any red-team testing that the company has conducted relating to lowering the barrier to entry for the development, acquisition, and use of biological weapons by non-state actors; the discovery of software vulnerabilities and development of associated exploits; the use of software or tools to influence real or virtual events; the possibility for self-replication or propagation; and associated measures to meet safety objectives; and","passage: (ii)\u00a0 Companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster to report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster.","passage: (b)\u00a0 The Secretary of Commerce, in consultation with the Secretary of State, the Secretary of Defense, the Secretary of Energy, and the Director of National Intelligence, shall define, and thereafter update as needed on a regular basis, the set of technical conditions for models and computing clusters that would be subject to the reporting requirements of subsection 4.2(a) of this section.\u00a0 Until such technical conditions are defined, the Secretary shall require compliance with these reporting requirements for:","passage: (i)\u00a0 \u00a0any model that was trained using a quantity of computing power greater than 1026\u00a0integer or floating-point operations, or using primarily biological sequence data and using a quantity of computing power greater than 1023\u00a0integer or floating-point operations; and","passage: (ii)\u00a0 any computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum computing capacity of 1020\u00a0integer or floating-point operations per second for training AI.","passage: (c)\u00a0 Because I find that additional steps must be taken to deal with the national emergency related to significant malicious cyber-enabled activities declared in Executive Order 13694 of April 1, 2015 (Blocking the Property of Certain Persons Engaging in Significant Malicious Cyber-Enabled Activities), as amended by Executive Order 13757 of December 28, 2016 (Taking Additional Steps to Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities), and further amended by Executive Order 13984, to address the use of United States Infrastructure as a Service (IaaS) Products by foreign malicious cyber actors, including to impose additional record-keeping obligations with respect to foreign transactions and to assist in the investigation of transactions involving foreign malicious cyber actors, I hereby direct the Secretary of Commerce, within 90 days of the date of this order, to:","passage: (i) \u00a0\u00a0\u00a0Propose regulations that require United States IaaS Providers to submit a report to the Secretary of Commerce when a foreign person transacts with that United States IaaS Provider to train a large AI model with potential capabilities that could be used in malicious cyber-enabled activity (a \u201ctraining run\u201d).\u00a0Such reports shall include, at a minimum, the identity of the foreign person and the existence of any training run of an AI model meeting the criteria set forth in this section, or other criteria defined by the Secretary in regulations, as well as any additional information identified by the Secretary.","passage: (ii) \u00a0\u00a0Include a requirement in the regulations proposed pursuant to subsection 4.2(c)(i) of this section that United States IaaS Providers prohibit any foreign reseller of their United States IaaS Product from providing those products unless such foreign reseller submits to the United States IaaS Provider a report, which the United States IaaS Provider must provide to the Secretary of Commerce, detailing each instance in which a foreign person transacts with the foreign reseller to use the United States IaaS Product to conduct a training run described in subsection 4.2(c)(i) of this section.\u00a0 Such reports shall include, at a minimum, the information specified in subsection 4.2(c)(i) of this section as well as any additional information identified by the Secretary.","passage: (iii) \u00a0Determine the set of technical conditions for a large AI model to have potential capabilities that could be used in malicious cyber-enabled activity, and revise that determination as necessary and appropriate.\u00a0Until the Secretary makes such a determination, a model shall be considered to have potential capabilities that could be used in malicious cyber-enabled activity if it requires a quantity of computing power greater than 1026\u00a0integer or floating-point operations and is trained on a computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum compute capacity of 1020\u00a0integer or floating-point operations per second for training AI.","passage: (d)\u00a0 Within 180 days of the date of this order, pursuant to the finding set forth in subsection 4.2(c) of this section, the Secretary of Commerce shall propose regulations that require United States IaaS Providers to ensure that foreign resellers of United States IaaS Products verify the identity of any foreign person that obtains an IaaS account (account) from the foreign reseller.\u00a0 These regulations shall, at a minimum:","passage: (i) \u00a0\u00a0\u00a0Set forth the minimum standards that a United States IaaS Provider must require of foreign resellers of its United States IaaS Products to verify the identity of a foreign person who opens an account or maintains an existing account with a foreign reseller, including:","passage: (A)\u00a0 the types of documentation and procedures that foreign resellers of United States IaaS Products must require to verify the identity of any foreign person acting as a lessee or sub-lessee of these products or services;","passage: (B)\u00a0 records that foreign resellers of United States IaaS Products must securely maintain regarding a foreign person that obtains an account, including information establishing:","passage: (1)\u00a0 the identity of such foreign person, including name and address;","passage: (2)\u00a0 the means and source of payment (including any associated financial institution and other identifiers such as credit card number, account number, customer identifier, transaction identifiers, or virtual currency wallet or wallet address identifier);","passage: (3)\u00a0 the electronic mail address and telephonic contact information used to verify a foreign person\u2019s identity; and","passage: (4)\u00a0 the Internet Protocol addresses used for access or administration and the date and time of each such access or administrative action related to ongoing verification of such foreign person\u2019s ownership of such an account; and","passage: (C)\u00a0 methods that foreign resellers of United States IaaS Products must implement to limit all third-party access to the information described in this subsection, except insofar as such access is otherwise consistent with this order and allowed under applicable law;","passage: (ii) \u00a0\u00a0Take into consideration the types of accounts maintained by foreign resellers of United States IaaS Products, methods of opening an account, and types of identifying information available to accomplish the objectives of identifying foreign malicious cyber actors using any such products and avoiding the imposition of an undue burden on such resellers; and","passage: (iii)\u00a0 Provide that the Secretary of Commerce, in accordance with such standards and procedures as the Secretary may delineate and in consultation with the Secretary of Defense, the Attorney General, the Secretary of Homeland Security, and the Director of National Intelligence, may exempt a United States IaaS Provider with respect to any specific foreign reseller of their United States IaaS Products, or with respect to any specific type of account or lessee, from the requirements of any regulation issued pursuant to this subsection.\u00a0 Such standards and procedures may include a finding by the Secretary that such foreign reseller, account, or lessee complies with security best practices to otherwise deter abuse of United States IaaS Products.","passage: (e) \u00a0The Secretary of Commerce is hereby authorized to take such actions, including the promulgation of rules and regulations, and to employ all powers granted to the President by the International Emergency Economic Powers Act, 50 U.S.C. 1701\u00a0_et seq._,as may be necessary to carry out the purposes of subsections 4.2(c) and (d) of this section.\u00a0 Such actions may include a requirement that United States IaaS Providers require foreign resellers of United States IaaS Products to provide United States IaaS Providers verifications relative to those subsections.","passage: 4.3.\u00a0 Managing AI in Critical Infrastructure and in Cybersecurity.\u00a0 (a)\u00a0 To ensure the protection of critical","passage: infrastructure, the following actions shall be taken:","passage: (i) \u00a0\u00a0\u00a0Within 90 days of the date of this order, and at least annually thereafter, the head of each agency with relevant regulatory authority over critical infrastructure and the heads of relevant SRMAs, in coordination with the Director of the Cybersecurity and Infrastructure Security Agency within the Department of Homeland Security for consideration of cross-sector risks, shall evaluate and provide to the Secretary of Homeland Security an assessment of potential risks related to the use of AI in critical infrastructure sectors involved, including ways in which deploying AI may make critical infrastructure systems more vulnerable to critical failures, physical attacks, and cyber attacks, and shall consider ways to mitigate these vulnerabilities.\u00a0 Independent regulatory agencies are encouraged, as they deem appropriate, to contribute to sector-specific risk assessments.","passage: (ii) \u00a0\u00a0Within 150 days of the date of this order, the Secretary of the Treasury shall issue a public report on best practices for financial institutions to manage AI-specific cybersecurity risks.","passage: (iii)\u00a0 Within 180 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of Commerce and with SRMAs and other regulators as determined by the Secretary of Homeland Security, shall incorporate as appropriate the AI Risk Management Framework, NIST AI 100-1, as well as other appropriate security guidance, into relevant safety and security guidelines for use by critical infrastructure owners and operators.","passage: (iv)\u00a0 \u00a0Within 240 days of the completion of the guidelines described in subsection 4.3(a)(iii) of this section, the Assistant to the President for National Security Affairs and the Director of OMB, in consultation with the Secretary of Homeland Security, shall coordinate work by the heads of agencies with authority over critical infrastructure to develop and take steps for the Federal Government to mandate such guidelines, or appropriate portions thereof, through regulatory or other appropriate action.\u00a0 Independent regulatory agencies are encouraged, as they deem appropriate, to consider whether to mandate guidance through regulatory action in their areas of authority and responsibility.","passage: (v) \u00a0\u00a0\u00a0The Secretary of Homeland Security shall establish an Artificial Intelligence Safety and Security Board as an advisory committee pursuant to section 871 of the Homeland Security Act of 2002 (Public Law 107-296).\u00a0 The Advisory Committee shall include AI experts from the private sector, academia, and government, as appropriate, and provide to the Secretary of Homeland Security and the Federal Government\u2019s critical infrastructure community advice, information, or recommendations for improving security, resilience, and incident response related to AI usage in critical infrastructure.","passage: (b)\u00a0 To capitalize on AI\u2019s potential to improve United States cyber defenses:","passage: (i) \u00a0\u00a0\u00a0The Secretary of Defense shall carry out the actions described in subsections 4.3(b)(ii) and (iii) of this section for national security systems, and the Secretary of Homeland Security shall carry out these actions for non-national security systems.\u00a0 Each shall do so in consultation with the heads of other relevant agencies as the Secretary of Defense and the Secretary of Homeland Security may deem appropriate.","passage: (ii) \u00a0\u00a0As set forth in subsection 4.3(b)(i) of this section, within 180 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall, consistent with applicable law, each develop plans for, conduct, and complete an operational pilot project to identify, develop, test, evaluate, and deploy AI capabilities, such as large-language models, to aid in the discovery and remediation of vulnerabilities in critical United States Government software, systems, and networks.","passage: (iii)\u00a0 As set forth in subsection 4.3(b)(i) of this section, within 270 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall each provide a report to the Assistant to the President for National Security Affairs on the results of actions taken pursuant to the plans and operational pilot projects required by subsection 4.3(b)(ii) of this section, including a description of any vulnerabilities found and fixed through the development and deployment of AI capabilities and any lessons learned on how to identify, develop, test, evaluate, and deploy AI capabilities effectively for cyber defense.","passage: 4.4.\u00a0 Reducing Risks at the Intersection of AI and CBRN Threats.\u00a0 (a)\u00a0 To better understand and mitigate the risk of AI being misused to assist in the development or use of CBRN threats \u2014 with a particular focus on biological weapons \u2014 the following actions shall be taken:","passage: (i) \u00a0\u00a0Within 180 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of Energy and the Director of the Office of Science and Technology Policy (OSTP), shall evaluate the potential for AI to be misused to enable the development or production of CBRN threats, while also considering the benefits and application of AI to counter these threats, including, as appropriate, the results of work conducted under section 8(b) of this order.\u00a0 The Secretary of Homeland Security shall:","passage: (A)\u00a0 consult with experts in AI and CBRN issues from the Department of Energy, private AI laboratories, academia, and third-party model evaluators, as appropriate, to evaluate AI model capabilities to present CBRN threats \u2014 for the sole purpose of guarding against those threats \u2014 as well as options for minimizing the risks of AI model misuse to generate or exacerbate those threats; and","passage: (B)\u00a0 submit a report to the President that describes the progress of these efforts, including an assessment of the types of AI models that may present CBRN risks to the United States, and that makes recommendations for regulating or overseeing the training, deployment, publication, or use of these models, including requirements for safety evaluations and guardrails for mitigating potential threats to national security.","passage: (ii)\u00a0 Within 120 days of the date of this order, the Secretary of Defense, in consultation with the Assistant to the President for National Security Affairs and the Director of OSTP, shall enter into a contract with the National Academies of Sciences, Engineering, and Medicine to conduct \u2014 and submit to the Secretary of Defense, the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, the Director of OSTP, and the Chair of the Chief Data Officer Council \u2014 a study that:","passage: (A)\u00a0 assesses the ways in which AI can increase biosecurity risks, including risks from generative AI models trained on biological data, and makes recommendations on how to mitigate these risks;","passage: (B)\u00a0 considers the national security implications of the use of data and datasets, especially those associated with pathogens and omics studies, that the United States Government hosts, generates, funds the creation of, or otherwise owns, for the training of generative AI models, and makes recommendations on how to mitigate the risks related to the use of these data and datasets;","passage: (C)\u00a0 assesses the ways in which AI applied to biology can be used to reduce biosecurity risks, including recommendations on opportunities to coordinate data and high-performance computing resources; and","passage: (D)\u00a0 considers additional concerns and opportunities at the intersection of AI and synthetic biology that the Secretary of Defense deems appropriate.","passage: (b)\u00a0 To reduce the risk of misuse of synthetic nucleic acids, which could be substantially increased by AI\u2019s capabilities in this area, and improve biosecurity measures for the nucleic acid synthesis industry, the following actions shall be taken:","passage: (i) \u00a0\u00a0\u00a0Within 180 days of the date of this order, the Director of OSTP, in consultation with the Secretary of State, the Secretary of Defense, the Attorney General, the Secretary of Commerce, the Secretary of Health and Human Services (HHS), the Secretary of Energy, the Secretary of Homeland Security, the Director of National Intelligence, and the heads of other relevant agencies as the Director of OSTP may deem appropriate, shall establish a framework, incorporating, as appropriate, existing United States Government guidance, to encourage providers of synthetic nucleic acid sequences to implement comprehensive, scalable, and verifiable synthetic nucleic acid procurement screening mechanisms, including standards and recommended incentives.\u00a0 As part of this framework, the Director of OSTP shall:","passage: (A)\u00a0 establish criteria and mechanisms for ongoing identification of biological sequences that could be used in a manner that would pose a risk to the national security of the United States; and","passage: (B)\u00a0 determine standardized methodologies and tools for conducting and verifying the performance of sequence synthesis procurement screening, including customer screening approaches to support due diligence with respect to managing security risks posed by purchasers of biological sequences identified in subsection 4.4(b)(i)(A) of this section, and processes for the reporting of concerning activity to enforcement entities.","passage: (ii) \u00a0\u00a0Within 180 days of the date of this order, the Secretary of Commerce, acting through the Director of NIST, in coordination with the Director of OSTP, and in consultation with the Secretary of State, the Secretary of HHS, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall initiate an effort to engage with industry and relevant stakeholders, informed by the framework developed under subsection 4.4(b)(i) of this section, to develop and refine for possible use by synthetic nucleic acid sequence providers:","passage: (A) \u00a0specifications for effective nucleic acid synthesis procurement screening;","passage: (B) \u00a0best practices, including security and access controls, for managing sequence-of-concern databases to support such screening;","passage: (C) \u00a0technical implementation guides for effective screening; and","passage: (D) \u00a0conformity-assessment best practices and mechanisms.","passage: (iii)\u00a0 Within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, all agencies that fund life-sciences research shall, as appropriate and consistent with applicable law, establish that, as a requirement of funding, synthetic nucleic acid procurement is conducted through providers or manufacturers that adhere to the framework, such as through an attestation from the provider or manufacturer.\u00a0The Assistant to the President for National Security Affairs and the Director of OSTP shall coordinate the process of reviewing such funding requirements to facilitate consistency in implementation of the framework across funding agencies.","passage: (iv) \u00a0\u00a0In order to facilitate effective implementation of the measures described in subsections 4.4(b)(i)-(iii) of this section, the Secretary of Homeland Security, in consultation with the heads of other relevant agencies as the Secretary of Homeland Security may deem appropriate, shall:","passage: (A)\u00a0 within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, develop a framework to conduct structured evaluation and stress testing of nucleic acid synthesis procurement screening, including the systems developed in accordance with subsections 4.4(b)(i)-(ii) of this section and implemented by providers of synthetic nucleic acid sequences; and","passage: (B)\u00a0 following development of the framework pursuant to subsection 4.4(b)(iv)(A) of this section, submit an annual report to the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, and the Director of OSTP on any results of the activities conducted pursuant to subsection 4.4(b)(iv)(A) of this section, including recommendations, if any, on how to strengthen nucleic acid synthesis procurement screening, including customer screening systems.","passage: 4.5.\u00a0 Reducing the Risks Posed by Synthetic Content.","passage: ![](https://www.whitehouse.gov/wp-content/uploads/2023/10/image.gif \"Anchor\")","passage: ![](https://www.whitehouse.gov/wp-content/uploads/2023/10/image.gif \"Anchor\")","passage: To foster capabilities for identifying and labeling synthetic content produced by AI systems, and to establish the authenticity and provenance of digital content, both synthetic and not synthetic, produced by the Federal Government or on its behalf:","passage: (a)\u00a0 Within 240 days of the date of this order, the Secretary of Commerce, in consultation with the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall submit a report to the Director of OMB and the Assistant to the President for National Security Affairs identifying the existing standards, tools, methods, and practices, as well as the potential development of further science-backed standards and techniques, for:","passage: (i) \u00a0\u00a0\u00a0authenticating content and tracking its provenance;","passage: (ii)\u00a0 \u00a0labeling synthetic content, such as using watermarking;","passage: (iii)\u00a0 detecting synthetic content;","passage: (iv) \u00a0\u00a0preventing generative AI from producing child sexual abuse material or producing non-consensual intimate imagery of real individuals (to include intimate digital depictions of the body or body parts of an identifiable individual);","passage: (v) \u00a0\u00a0\u00a0testing software used for the above purposes; and","passage: (vi) \u00a0\u00a0auditing and maintaining synthetic content.","passage: (b)\u00a0 Within 180 days of submitting the report required under subsection 4.5(a) of this section, and updated periodically thereafter, the Secretary of Commerce, in coordination with the Director of OMB, shall develop guidance regarding the existing tools and practices for digital content authentication and synthetic content detection measures.\u00a0 The guidance shall include measures for the purposes listed in subsection 4.5(a) of this section.","passage: (c)\u00a0 Within 180 days of the development of the guidance required under subsection 4.5(b) of this section, and updated periodically thereafter, the Director of OMB, in consultation with the Secretary of State; the Secretary of Defense; the Attorney General; the Secretary of Commerce, acting through the Director of NIST; the Secretary of Homeland Security; the Director of National Intelligence; and the heads of other agencies that the Director of OMB deems appropriate, shall \u2014 for the purpose of strengthening public confidence in the\u00a0integrity of official United States Government digital content \u2014 issue guidance to agencies for labeling and authenticating such content that they produce or publish.","passage: (d)\u00a0 The Federal Acquisition Regulatory Council shall, as appropriate and consistent with applicable law, consider amending the Federal Acquisition Regulation to take into account the guidance established under subsection 4.5 of this section.","passage: 4.6.\u00a0 Soliciting Input on Dual-Use Foundation Models with Widely Available Model Weights.\u00a0 When the weights for a dual-use foundation model are widely available \u2014 such as when they are publicly posted on the Internet \u2014 there can be substantial benefits to innovation, but also substantial security risks, such as the removal of safeguards within the model.\u00a0To address the risks and potential benefits of dual-use foundation models with widely available weights, within 270 days of the date of this order, the Secretary of Commerce, acting through the Assistant Secretary of Commerce for Communications and Information, and in consultation with the Secretary of State, shall:","passage: (a)\u00a0 solicit input from the private sector, academia, civil society, and other stakeholders through a public consultation process on potential risks, benefits, other implications, and appropriate policy and regulatory approaches related to dual-use foundation models for which the model weights are widely available, including:","passage: (i)\u00a0 \u00a0\u00a0risks associated with actors fine-tuning dual-use foundation models for which the model weights are widely available or removing those models\u2019 safeguards;","passage: (ii)\u00a0 \u00a0benefits to AI innovation and research, including research into AI safety and risk management, of dual-use foundation models for which the model weights are widely available; and","passage: (iii)\u00a0 potential voluntary, regulatory, and international mechanisms to manage the risks and maximize the benefits of dual-use foundation models for which the model weights are widely available; and","passage: (b)\u00a0 based on input from the process described in subsection 4.6(a) of this section, and in consultation with the heads of other relevant agencies as the Secretary of Commerce deems appropriate, submit a report to the President on the potential benefits, risks, and implications of dual-use foundation models for which the model weights are widely available, as well as policy and regulatory recommendations pertaining to those models.","passage: 4.7.\u00a0 Promoting Safe Release and Preventing the Malicious Use of Federal Data for AI Training.To improve public data access and manage security risks, and consistent with the objectives of the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435) to expand public access to Federal data assets in a machine-readable format while also taking into account security considerations, including the risk that information in an individual data asset in isolation does not pose a security risk but, when combined with other available information, may pose such a risk:","passage: (a)\u00a0 within 270 days of the date of this order, the Chief Data Officer Council, in consultation with the Secretary of Defense, the Secretary of Commerce, the Secretary of Energy, the Secretary of Homeland Security, and the Director of National Intelligence, shall develop initial guidelines for performing security reviews, including reviews to identify and manage the potential security risks of releasing Federal data that could aid in the development of CBRN weapons as well as the development of autonomous offensive cyber capabilities, while also providing public access to Federal Government data in line with the goals stated in the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435); and","passage: (b)\u00a0 within 180 days of the development of the initial guidelines required by subsection 4.7(a) of this section, agencies shall conduct a security review of all data assets in the comprehensive data inventory required under 44 U.S.C. 3511(a)(1) and (2)(B) and shall take steps, as appropriate and consistent with applicable law, to address the highest-priority potential security risks that releasing that data could raise with respect to CBRN weapons, such as the ways in which that data could be used to train AI systems.","passage: 4.8.\u00a0 Directing the Development of a National Security Memorandum.\u00a0 To develop a coordinated executive branch approach to managing AI\u2019s security risks, the Assistant to the President for National Security Affairs and the Assistant to the President and Deputy Chief of Staff for Policy shall oversee an interagency process with the purpose of, within 270 days of the date of this order, developing and submitting a proposed National Security Memorandum on AI to the President.\u00a0 The memorandum shall address the governance of AI used as a component of a national security system or for military and intelligence purposes.\u00a0 The memorandum shall take into account current efforts to govern the development and use of AI for national security systems.\u00a0 The memorandum shall outline actions for the Department of Defense, the Department of State, other relevant agencies, and the Intelligence Community to address the national security risks and potential benefits posed by AI.\u00a0 In particular, the memorandum shall:","passage: (a)\u00a0 provide guidance to the Department of Defense, other relevant agencies, and the Intelligence Community on the continued adoption of AI capabilities to advance the United States national security mission, including through directing specific AI assurance and risk-management practices for national security uses of AI that may affect the rights or safety of United States persons and, in appropriate contexts, non-United States persons; and","passage: (b)\u00a0 direct continued actions, as appropriate and consistent with applicable law, to address the potential use of AI systems by adversaries and other foreign actors in ways that threaten the capabilities or objectives of the Department of Defense or the Intelligence Community, or that otherwise pose risks to the security of the United States or its allies and partners.","passage: Sec.5.Promoting Innovation and Competition.","passage: 5.1.\u00a0 Attracting AI Talent to the United States.\u00a0 (a)\u00a0 Within 90 days of the date of this order, to attract and retain talent in AI and other critical and emerging technologies in the United States economy, the Secretary of State and the Secretary of Homeland Security shall take appropriate steps to:","passage: (i) \u00a0\u00a0streamline processing times of visa petitions and applications, including by ensuring timely availability of visa appointments, for noncitizens who seek to travel to the United States to work on, study, or conduct research in AI or other critical and emerging technologies; and","passage: (ii)\u00a0 facilitate continued availability of visa appointments in sufficient volume for applicants with expertise in AI or other critical and emerging technologies.","passage: (b)\u00a0 Within 120 days of the date of this order, the Secretary of State shall:","passage: (i) \u00a0\u00a0\u00a0consider initiating a rulemaking to establish new criteria to designate countries and skills on the Department of State\u2019s Exchange Visitor Skills List as it relates to the 2-year foreign residence requirement for certain J-1 nonimmigrants, including those skills that are critical to the United States;","passage: (ii) \u00a0\u00a0consider publishing updates to the 2009 Revised Exchange Visitor Skills List (74 FR 20108); and","passage: (iii)\u00a0 consider implementing a domestic visa renewal program under 22 C.F.R. 41.111(b) to facilitate the ability of qualified applicants, including highly skilled talent in AI and critical and emerging technologies, to continue their work in the United States without unnecessary interruption.","passage: (c)\u00a0 Within 180 days of the date of this order, the Secretary of State shall:","passage: (i) \u00a0\u00a0consider initiating a rulemaking to expand the categories of nonimmigrants who qualify for the domestic visa renewal program covered under 22 C.F.R. 41.111(b) to include academic J-1 research scholars and F-1 students in science, technology, engineering, and mathematics (STEM); and","passage: (ii)\u00a0 establish, to the extent permitted by law and available appropriations, a program to identify and attract top talent in AI and other critical and emerging technologies at universities, research institutions, and the private sector overseas, and to establish and increase connections with that talent to educate them on opportunities and resources for research and employment in the United States, including overseas educational components to inform top STEM talent of nonimmigrant and immigrant visa options and potential expedited adjudication of their visa petitions and applications.","passage: (d)\u00a0 Within 180 days of the date of this order, the Secretary of Homeland Security shall:","passage: (i) \u00a0\u00a0review and initiate any policy changes the Secretary determines necessary and appropriate to clarify and modernize immigration pathways for experts in AI and other critical and emerging technologies, including O-1A and EB-1 noncitizens of extraordinary ability; EB-2 advanced-degree holders and noncitizens of exceptional ability; and startup founders in AI and other critical and emerging technologies using the International Entrepreneur Rule; and","passage: (ii)\u00a0 continue its rulemaking process to modernize the H-1B program and enhance its integrity and usage, including by experts in AI and other critical and emerging technologies, and consider initiating a rulemaking to enhance the process for noncitizens, including experts in AI and other critical and emerging technologies and their spouses, dependents, and children, to adjust their status to lawful permanent resident.","passage: (e)\u00a0 Within 45 days of the date of this order, for purposes of considering updates to the \u201cSchedule A\u201d list of occupations, 20 C.F.R. 656.5, the Secretary of Labor shall publish a request for information (RFI) to solicit public input, including from industry and worker-advocate communities, identifying AI and other STEM-related occupations, as well as additional occupations across the economy, for which there is an insufficient number of ready, willing, able, and qualified United States workers.","passage: (f)\u00a0 The Secretary of State and the Secretary of Homeland Security shall, consistent with applicable law and implementing regulations, use their discretionary authorities to support and attract foreign nationals with special skills in AI and other critical and emerging technologies seeking to work, study, or conduct research in the United States.","passage: (g)\u00a0 Within 120 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of State, the Secretary of Commerce, and the Director of OSTP, shall develop and publish informational resources to better attract and retain experts in AI and other critical and emerging technologies, including:","passage: (i) \u00a0\u00a0a clear and comprehensive guide for experts in AI and other critical and emerging technologies to understand their options for working in the United States, to be published in multiple relevant languages on AI.gov; and","passage: (ii)\u00a0 a public report with relevant data on applications, petitions, approvals, and other key indicators of how experts in AI and other critical and emerging technologies have utilized the immigration system through the end of Fiscal Year 2023.","passage: 5.2.\u00a0 Promoting Innovation.\u00a0 (a)\u00a0 To develop and strengthen public-private partnerships for advancing innovation, commercialization, and risk-mitigation methods for AI, and to help promote safe, responsible, fair, privacy-protecting, and trustworthy AI systems, the Director of NSF shall take the following steps:","passage: (i) \u00a0\u00a0\u00a0Within 90 days of the date of this order, in coordination with the heads of agencies that the Director of NSF deems appropriate, launch a pilot program implementing the National AI Research Resource (NAIRR), consistent with past recommendations of the NAIRR Task Force.\u00a0 The program shall pursue the infrastructure, governance mechanisms, and user interfaces to pilot an initial integration of distributed computational, data, model, and training resources to be made available to the research community in support of AI-related research and development.\u00a0 The Director of NSF shall identify Federal and private sector computational, data, software, and training resources appropriate for inclusion in the NAIRR pilot program.\u00a0 To assist with such work, within 45 days of the date of this order, the heads of agencies whom the Director of NSF identifies for coordination pursuant to this subsection shall each submit to the Director of NSF a report identifying the agency resources that could be developed and integrated into such a pilot program.\u00a0 These reports shall include a description of such resources, including their current status and availability; their format, structure, or technical specifications; associated agency expertise that will be provided; and the benefits and risks associated with their inclusion in the NAIRR pilot program.\u00a0 The heads of independent regulatory agencies are encouraged to take similar steps, as they deem appropriate.","passage: (ii) \u00a0\u00a0Within 150 days of the date of this order, fund and launch at least one NSF Regional Innovation Engine that prioritizes AI-related work, such as AI-related research, societal, or workforce needs.","passage: (iii)\u00a0 Within 540 days of the date of this order, establish at least four new National AI Research Institutes, in addition to the 25 currently funded as of the date of this order.","passage: (b)\u00a0 Within 120 days of the date of this order, to support activities involving high-performance and data-intensive computing, the Secretary of Energy, in coordination with the Director of NSF, shall, in a manner consistent with applicable law and available appropriations, establish a pilot program to enhance existing successful training programs for scientists, with the goal of training 500 new researchers by 2025 capable of meeting the rising demand for AI talent.","passage: (c)\u00a0 To promote innovation and clarify issues related to AI and inventorship of patentable subject matter, the Under Secretary of Commerce for Intellectual Property and Director of the United States Patent and Trademark Office (USPTO Director) shall:","passage: (i)\u00a0 \u00a0\u00a0within 120 days of the date of this order, publish guidance to USPTO patent examiners and applicants addressing inventorship and the use of AI, including generative AI, in the inventive process, including illustrative examples in which AI systems play different roles in inventive processes and how, in each example, inventorship issues ought to be analyzed;","passage: (ii) \u00a0\u00a0subsequently, within 270 days of the date of this order, issue additional guidance to USPTO patent examiners and applicants to address other considerations at the intersection of AI and IP, which could include, as the USPTO Director deems necessary, updated guidance on patent eligibility to address innovation in AI and critical and emerging technologies; and","passage: (iii)\u00a0 within 270 days of the date of this order or 180 days after the\u00a0United States Copyright Office of the Library of Congress publishes its forthcoming AI study that will address copyright issues raised by AI, whichever comes later, consult with the Director of the United States Copyright Office and issue recommendations to the President on potential executive actions relating to copyright and AI.\u00a0 The recommendations shall address any copyright and related issues discussed in the United States Copyright Office\u2019s study, including the scope of protection for works produced using AI and the treatment of copyrighted works in AI training.","passage: (d)\u00a0 Within 180 days of the date of this order, to assist developers of AI in combatting AI-related IP risks, the Secretary of Homeland Security, acting through the Director of the National Intellectual Property Rights Coordination Center, and in consultation with the Attorney General, shall develop a training, analysis, and evaluation program to mitigate AI-related IP risks.\u00a0 Such a program shall:","passage: (i)\u00a0 \u00a0\u00a0include appropriate personnel dedicated to collecting and analyzing reports of AI-related IP theft, investigating such incidents with implications for national security, and, where appropriate and consistent with applicable law, pursuing related enforcement actions;","passage: (ii) \u00a0\u00a0implement a policy of sharing information and coordinating on such work, as appropriate and consistent with applicable law, with the Federal Bureau of Investigation; United States Customs and Border Protection; other agencies; State and local agencies; and appropriate international organizations, including through work-sharing agreements;","passage: (iii)\u00a0 develop guidance and other appropriate resources to assist private sector actors with mitigating the risks of AI-related IP theft;","passage: (iv) \u00a0\u00a0share information and best practices with AI developers and law enforcement personnel to identify incidents, inform stakeholders of current legal requirements, and evaluate AI systems for IP law violations, as well as develop mitigation strategies and resources; and","passage: (v) \u00a0\u00a0\u00a0assist the Intellectual Property Enforcement Coordinator in updating the Intellectual Property Enforcement Coordinator Joint Strategic Plan on Intellectual Property Enforcement to address AI-related issues.","passage: (e)\u00a0 To advance responsible AI innovation by a wide range of healthcare technology developers that promotes the welfare of patients and workers in the healthcare sector, the Secretary of HHS shall identify and, as appropriate and consistent with applicable law and the activities directed in section 8 of this order, prioritize grantmaking and other awards, as well as undertake related efforts, to support responsible AI development and use, including:","passage: (i) \u00a0\u00a0\u00a0collaborating with appropriate private sector actors through HHS programs that may support the advancement of AI-enabled tools that develop personalized immune-response profiles for patients, consistent with section 4 of this order;","passage: (ii) \u00a0\u00a0prioritizing the allocation of 2024 Leading Edge Acceleration Project cooperative agreement awards to initiatives that explore ways to improve healthcare-data quality to support the responsible development of AI tools for clinical care, real-world-evidence programs, population health, public health, and related research; and","passage: (iii)\u00a0 accelerating grants awarded through the National Institutes of Health Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity (AIM-AHEAD) program and showcasing current AIM-AHEAD activities in underserved communities.","passage: (f) \u00a0To advance the development of AI systems that improve the quality of veterans\u2019 healthcare, and in order to support small businesses\u2019 innovative capacity, the Secretary of Veterans Affairs shall:","passage: (i) \u00a0\u00a0within 365 days of the date of this order, host two 3-month nationwide AI Tech Sprint competitions; and","passage: (ii)\u00a0 as part of the AI Tech Sprint competitions and in collaboration with appropriate partners, provide participants access to technical assistance, mentorship opportunities, individualized expert feedback on products under development, potential contract opportunities, and other programming and resources.","passage: (g)\u00a0 Within 180 days of the date of this order, to support the goal of strengthening our Nation\u2019s resilience against climate change impacts and building an equitable clean energy economy for the future, the Secretary of Energy, in consultation with the Chair of the Federal Energy Regulatory Commission, the Director of OSTP, the Chair of the Council on Environmental Quality, the Assistant to the President and National Climate Advisor, and the heads of other relevant agencies as the Secretary of Energy may deem appropriate, shall:","passage: (i) \u00a0\u00a0\u00a0issue a public report describing the potential for AI to improve planning, permitting, investment, and operations for electric grid infrastructure and to enable the provision of clean, affordable, reliable, resilient, and secure electric power to all Americans;","passage: (ii) \u00a0\u00a0develop tools that facilitate building foundation models useful for basic and applied science, including models that streamline permitting and environmental reviews while improving environmental and social outcomes;","passage: (iii)\u00a0 collaborate, as appropriate, with private sector organizations and members of academia to support development of AI tools to mitigate climate change risks;","passage: (iv) \u00a0\u00a0take steps to expand partnerships with industry, academia, other agencies, and international allies and partners to utilize the Department of Energy\u2019s computing capabilities and AI testbeds to build foundation models that support new applications in science and energy, and for national security, including partnerships that increase community preparedness for climate-related risks, enable clean-energy deployment (including addressing delays in permitting reviews), and enhance grid reliability and resilience; and","passage: (v) \u00a0\u00a0\u00a0establish an office to coordinate development of AI and other critical and emerging technologies across Department of Energy programs and the 17 National Laboratories.","passage: (h)\u00a0 Within 180 days of the date of this order, to understand AI\u2019s implications for scientific research, the President\u2019s Council of Advisors on Science and Technology shall submit to the President and make publicly available a report on the potential role of AI, especially given recent developments in AI, in research aimed at tackling major societal and global challenges.\u00a0 The report shall include a discussion of issues that may hinder the effective use of AI in research and practices needed to ensure that AI is used responsibly for research.","passage: 5.3.\u00a0 Promoting Competition.\u00a0 (a)\u00a0 The head of each agency developing policies and regulations related to AI shall use their authorities, as appropriate and consistent with applicable law, to promote competition in AI and related technologies, as well as in other markets.\u00a0 Such actions include addressing risks arising from concentrated control of key inputs, taking steps to stop unlawful collusion and prevent dominant firms from disadvantaging competitors, and working to provide new opportunities for small businesses and entrepreneurs.\u00a0 In particular, the Federal Trade Commission is encouraged to consider, as it deems appropriate, whether to exercise the Commission\u2019s existing authorities, including its rulemaking authority under the Federal Trade Commission Act, 15 U.S.C. 41\u00a0_et seq_.,to ensure fair competition in the AI marketplace and to ensure that consumers and workers are protected from harms that may be enabled by the use of AI.","passage: (b)\u00a0 To promote competition and innovation in the semiconductor industry, recognizing that semiconductors power AI technologies and that their availability is critical to AI competition, the Secretary of Commerce shall, in implementing division A of Public Law 117-167, known as the Creating Helpful Incentives to Produce Semiconductors (CHIPS) Act of 2022, promote competition by:","passage: (i) \u00a0\u00a0\u00a0implementing a flexible membership structure for the National Semiconductor Technology Center that attracts all parts of the semiconductor and microelectronics ecosystem, including startups and small firms;","passage: (ii) \u00a0\u00a0implementing mentorship programs to increase interest and participation in the semiconductor industry, including from workers in underserved communities;","passage: (iii)\u00a0 increasing, where appropriate and to the extent permitted by law, the availability of resources to startups and small businesses, including:","passage: (A)\u00a0 funding for physical assets, such as specialty equipment or facilities, to which startups and small businesses may not otherwise have access;","passage: (B)\u00a0 datasets \u2014 potentially including test and performance data \u2014 collected, aggregated, or shared by CHIPS research and development programs;","passage: (C)\u00a0 workforce development programs;","passage: (D)\u00a0 design and process technology, as well as IP, as appropriate; and","passage: (E)\u00a0 other resources, including technical and intellectual property assistance, that could accelerate commercialization of new technologies by startups and small businesses, as appropriate; and","passage: (iv) \u00a0\u00a0considering the inclusion, to the maximum extent possible, and as consistent with applicable law, of competition-increasing measures in notices of funding availability for commercial research-and-development facilities focused on semiconductors, including measures that increase access to facility capacity for startups or small firms developing semiconductors used to power AI technologies.","passage: (c)\u00a0 To support small businesses innovating and commercializing AI, as well as in responsibly adopting and deploying AI, the Administrator of the Small Business Administration shall:","passage: (i) \u00a0\u00a0\u00a0prioritize the allocation of Regional Innovation Cluster program funding for clusters that support planning activities related to the establishment of one or more Small Business AI Innovation and Commercialization Institutes that provide support, technical assistance, and other resources to small businesses seeking to innovate, commercialize, scale, or otherwise advance the development of AI;","passage: (ii) \u00a0\u00a0prioritize the allocation of up to $2 million in Growth Accelerator Fund Competition bonus prize funds for accelerators that support the incorporation or expansion of AI-related curricula, training, and technical assistance, or other AI-related resources within their programming; and","passage: (iii)\u00a0 assess the extent to which the eligibility criteria of existing programs, including the State Trade Expansion Program, Technical and Business Assistance funding, and capital-access programs \u2014 such as the 7(a) loan program, 504 loan program, and Small Business Investment Company (SBIC) program \u2014 support appropriate expenses by small businesses related to the adoption of AI and, if feasible and appropriate, revise eligibility criteria to improve support for these expenses.","passage: (d)\u00a0 The Administrator of the Small Business Administration, in coordination with resource partners, shall conduct outreach regarding, and raise awareness of, opportunities for small businesses to use capital-access programs described in subsection 5.3(c) of this section for eligible AI-related purposes, and for eligible investment funds with AI-related expertise \u2014 particularly those seeking to serve or with experience serving underserved communities \u2014 to apply for an SBIC license.","passage: Sec.6.\u00a0Supporting Workers.(a)\u00a0 To advance the Government\u2019s understanding of AI\u2019s implications for workers, the following actions shall be taken within 180 days of the date of this order:","passage: (i) \u00a0\u00a0The Chairman of the Council of Economic Advisers shall prepare and submit a report to the President on the labor-market effects of AI.","passage: (ii)\u00a0 To evaluate necessary steps for the Federal Government to address AI-related workforce disruptions, the Secretary of Labor shall submit to the President a report analyzing the abilities of agencies to support workers displaced by the adoption of AI and other technological advancements.\u00a0The report shall, at a minimum:","passage: (A)\u00a0 assess how current or formerly operational Federal programs designed to assist workers facing job disruptions \u2014 including unemployment insurance and programs authorized by the Workforce Innovation and Opportunity Act (Public Law 113-128) \u2014 could be used to respond to possible future AI-related disruptions; and","passage: (B)\u00a0 identify options, including potential legislative measures, to strengthen or develop additional Federal support for workers displaced by AI and, in consultation with the Secretary of Commerce and the Secretary of Education, strengthen and expand education and training opportunities that provide individuals pathways to occupations related to AI.","passage: (b)\u00a0 To help ensure that AI deployed in the workplace advances employees\u2019 well-being:","passage: (i) \u00a0\u00a0\u00a0The Secretary of Labor shall, within 180 days of the date of this order and in consultation with other agencies and with outside entities, including labor unions and workers, as the Secretary of Labor deems appropriate, develop and publish principles and best practices for employers that could be used to mitigate AI\u2019s potential harms to employees\u2019 well-being and maximize its potential benefits.\u00a0The principles and best practices shall include specific steps for employers to take with regard to AI, and shall cover, at a minimum:","passage: (A)\u00a0 job-displacement risks and career opportunities related to AI, including effects on job skills and evaluation of applicants and workers;","passage: (B)\u00a0 labor standards and job quality, including issues related to the equity, protected-activity, compensation, health, and safety implications of AI in the workplace; and","passage: (C)\u00a0 implications for workers of employers\u2019 AI-related collection and use of data about them, including transparency, engagement, management, and activity protected under worker-protection laws.","passage: (ii) \u00a0\u00a0After principles and best practices are developed pursuant to subsection (b)(i) of this section, the heads of agencies shall consider, in consultation with the Secretary of Labor, encouraging the adoption of these guidelines in their programs to the extent appropriate for each program and consistent with applicable law.","passage: (iii)\u00a0 To support employees whose work is monitored or augmented by AI in being compensated appropriately for all of their work time, the Secretary of Labor shall issue guidance to make clear that employers that deploy AI to monitor or augment employees\u2019 work must continue to comply with protections that ensure that workers are compensated for their hours worked, as defined under the Fair Labor Standards Act of 1938, 29 U.S.C. 201\u00a0_et seq._,and other legal requirements.","passage: (c)\u00a0 To foster a diverse AI-ready workforce, the Director of NSF shall prioritize available resources to support AI-related education and AI-related workforce development through existing programs.\u00a0The Director shall additionally consult with agencies, as appropriate, to identify further opportunities for agencies to allocate resources for those purposes.\u00a0The actions by the Director shall use appropriate fellowship programs and awards for these purposes.","passage: Sec.7.\u00a0Advancing Equity and Civil Rights.","passage: 7.1.\u00a0Strengthening AI and Civil Rights in the Criminal Justice System.\u00a0 (a)\u00a0 To address unlawful discrimination and other harms that may be exacerbated by AI, the Attorney General shall:","passage: (i) \u00a0\u00a0\u00a0consistent with Executive Order 12250 of November 2, 1980 (Leadership and Coordination of Nondiscrimination Laws), Executive Order 14091, and 28 C.F.R. 0.50-51, coordinate with and support agencies in their implementation and enforcement of existing Federal laws to address civil rights and civil liberties violations and discrimination related to AI;","passage: (ii) \u00a0\u00a0direct the Assistant Attorney General in charge of the Civil Rights Division to convene, within 90 days of the date of this order, a meeting of the heads of Federal civil rights offices \u2014 for which meeting the heads of civil rights offices within independent regulatory agencies will be encouraged to join \u2014 to discuss comprehensive use of their respective authorities and offices to: \u00a0prevent and address discrimination in the use of automated systems, including algorithmic discrimination; increase coordination between the Department of Justice\u2019s Civil Rights Division and Federal civil rights offices concerning issues related to AI and algorithmic discrimination; improve external stakeholder engagement to promote public awareness of potential discriminatory uses and effects of AI; and develop, as appropriate, additional training, technical assistance, guidance, or other resources; and","passage: (iii)\u00a0 consider providing, as appropriate and consistent with applicable law, guidance, technical assistance, and training to State, local, Tribal, and territorial investigators and prosecutors on best practices for investigating and prosecuting civil rights violations and discrimination related to automated systems, including AI.","passage: (b)\u00a0 To promote the equitable treatment of individuals and adhere to the Federal Government\u2019s fundamental obligation to ensure fair and impartial justice for all, with respect to the use of AI in the criminal justice system, the Attorney General shall, in consultation with the Secretary of Homeland Security and the Director of OSTP:","passage: (i)\u00a0 \u00a0\u00a0within 365 days of the date of this order, submit to the President a report that addresses the use of AI in the criminal justice system, including any use in:","passage: (A) \u00a0sentencing;","passage: (B)\u00a0 parole, supervised release, and probation;","passage: (C)\u00a0 bail, pretrial release, and pretrial detention;","passage: (D)\u00a0 risk assessments, including pretrial, earned time, and early release or transfer to home-confinement determinations;","passage: (E)\u00a0 police surveillance;","passage: (F) \u00a0crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high-density \u201chot spots\u201d;","passage: (G) \u00a0prison-management tools; and","passage: (H)\u00a0 forensic analysis;","passage: (ii) \u00a0\u00a0within the report set forth in subsection 7.1(b)(i) of this section:","passage: (A)\u00a0 identify areas where AI can enhance law enforcement efficiency and accuracy, consistent with protections for privacy, civil rights, and civil liberties; and","passage: (B)\u00a0 recommend best practices for law enforcement agencies, including safeguards and appropriate use limits for AI, to address the concerns set forth in section 13(e)(i) of Executive Order 14074 as well as the best practices and the guidelines set forth in section 13(e)(iii) of Executive Order 14074; and","passage: (iii)\u00a0 supplement the report set forth in subsection 7.1(b)(i) of this section as appropriate with recommendations to the President, including with respect to requests for necessary legislation.","passage: (c)\u00a0 To advance the presence of relevant technical experts and expertise (such as machine-learning engineers, software and infrastructure engineering, data privacy experts, data scientists, and user experience researchers) among law enforcement professionals:","passage: (i) \u00a0\u00a0\u00a0The interagency working group created pursuant to section 3 of Executive Order 14074 shall, within 180 days of the date of this order, identify and share best practices for recruiting and hiring law enforcement professionals who have the technical skills mentioned in subsection 7.1(c) of this section, and for training law enforcement professionals about responsible application of AI.","passage: (ii) \u00a0\u00a0Within 270 days of the date of this order, the Attorney General shall, in consultation with the Secretary of Homeland Security, consider those best practices and the guidance developed under section 3(d) of Executive Order 14074 and, if necessary, develop additional general recommendations for State, local, Tribal, and territorial law enforcement agencies and criminal justice agencies seeking to recruit, hire, train, promote, and retain highly qualified and service-oriented officers and staff with relevant technical knowledge.\u00a0 In considering this guidance, the Attorney General shall consult with State, local, Tribal, and territorial law enforcement agencies, as appropriate.","passage: (iii)\u00a0 Within 365 days of the date of this order, the Attorney General shall review the work conducted pursuant to section 2(b) of Executive Order 14074 and, if appropriate, reassess the existing capacity to investigate law enforcement deprivation of rights under color of law resulting from the use of AI, including through improving and increasing training of Federal law enforcement officers, their supervisors, and Federal prosecutors on how to investigate and prosecute cases related to AI involving the deprivation of rights under color of law pursuant to 18 U.S.C. 242.","passage: 7.2.\u00a0Protecting Civil Rights Related to Government Benefits and Programs.\u00a0 (a)\u00a0 To advance equity and civil rights, consistent with the directives of Executive Order 14091, and in addition to complying with the guidance on Federal Government use of AI issued pursuant to section 10.1(b) of this order, agencies shall use their respective civil rights and civil liberties offices and authorities \u2014 as appropriate and consistent with applicable law \u2014 to prevent and address unlawful discrimination and other harms that result from uses of AI in Federal Government programs and benefits administration.\u00a0This directive does not apply to agencies\u2019 civil or criminal enforcement authorities.\u00a0 Agencies shall consider opportunities to ensure that their respective civil rights and civil liberties offices are appropriately consulted on agency decisions regarding the design, development, acquisition, and use of AI in Federal Government programs and benefits administration.\u00a0To further these objectives, agencies shall also consider opportunities to increase coordination, communication, and engagement about AI as appropriate with community-based organizations; civil-rights and civil-liberties organizations; academic institutions; industry; State, local, Tribal, and territorial governments; and other stakeholders.","passage: (b)\u00a0 To promote equitable administration of public benefits:","passage: (i) \u00a0\u00a0The Secretary of HHS shall, within 180 days of the date of this order and in consultation with relevant agencies, publish\u00a0a plan, informed by the guidance issued pursuant to section 10.1(b) of this order, addressing the use of automated or algorithmic systems in the implementation by States and localities of public benefits and services administered by the Secretary, such as to promote: \u00a0assessment of access to benefits by qualified recipients; notice to recipients about the presence of such systems; regular evaluation to detect unjust denials; processes to retain appropriate levels of discretion of expert agency staff; processes to appeal denials to human reviewers; and analysis of whether algorithmic systems in use by benefit programs achieve equitable and just outcomes.","passage: (ii)\u00a0 The Secretary of Agriculture shall, within 180 days of the date of this order and as informed by the guidance issued pursuant to section 10.1(b) of this order, issue guidance to State, local, Tribal, and territorial public-benefits administrators on the use of automated or algorithmic systems in implementing benefits or in providing customer support for benefit programs administered by the Secretary, to ensure that programs using those systems:","passage: (A)\u00a0 maximize program access for eligible recipients;","passage: (B)\u00a0 employ automated or algorithmic systems in a manner consistent with any requirements for using merit systems personnel in public-benefits programs;","passage: (C) \u00a0identify instances in which reliance on automated or algorithmic systems would require notification by the State, local, Tribal, or territorial government to the Secretary;","passage: (D)\u00a0 identify instances when applicants and participants can appeal benefit determinations to a human reviewer for reconsideration and can receive other customer support from a human being;","passage: (E) \u00a0enable auditing and, if necessary, remediation of the logic used to arrive at an individual decision or determination to facilitate the evaluation of appeals; and","passage: (F)\u00a0 enable the analysis of whether algorithmic systems in use by benefit programs achieve equitable outcomes.","passage: 7.3.\u00a0Strengthening AI and Civil Rights in the Broader Economy.\u00a0 (a)\u00a0 Within 365 days of the date of this order, to prevent unlawful discrimination from AI used for hiring, the Secretary of Labor shall publish guidance for Federal contractors regarding nondiscrimination in hiring involving AI and other technology-based hiring systems.","passage: (b)\u00a0 To address discrimination and biases against protected groups in housing markets and consumer financial markets, the Director of the Federal Housing Finance Agency and the Director of the Consumer Financial Protection Bureau are encouraged to consider using their authorities, as they deem appropriate, to require their respective regulated entities, where possible, to use appropriate methodologies including AI tools to ensure compliance with Federal law and:","passage: (i) \u00a0\u00a0evaluate their underwriting models for bias or disparities affecting protected groups; and","passage: (ii)\u00a0 evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.","passage: (c)\u00a0 Within 180 days of the date of this order, to combat unlawful discrimination enabled by automated or algorithmic tools used to make decisions about access to housing and in other real estate-related transactions, the Secretary of Housing and Urban Development shall, and the Director of the Consumer Financial Protection Bureau is encouraged to, issue additional guidance:","passage: (i) \u00a0\u00a0addressing the use of tenant screening systems in ways that may violate the Fair Housing Act (Public Law 90-284), the Fair Credit Reporting Act (Public Law 91-508), or other relevant Federal laws, including how the use of data, such as criminal records, eviction records, and credit information, can lead to discriminatory outcomes in violation of Federal law; and","passage: (ii)\u00a0 addressing how the Fair Housing Act, the Consumer Financial Protection Act of 2010 (title X of Public Law 111-203), or the Equal Credit Opportunity Act (Public Law 93-495) apply to the advertising of housing, credit, and other real estate-related transactions through digital platforms, including those that use algorithms to facilitate advertising delivery, as well as on best practices to avoid violations of Federal law.","passage: (d)\u00a0 To help ensure that people with disabilities benefit from AI\u2019s promise while being protected from its risks, including unequal treatment from the use of biometric data like gaze direction, eye tracking, gait analysis, and hand motions, the Architectural and Transportation Barriers Compliance Board is encouraged, as it deems appropriate, to solicit public participation and conduct community engagement; to issue technical assistance and recommendations on the risks and benefits of AI in using biometric data as an input; and to provide people with disabilities access to information and communication technology and transportation services.","passage: Sec.8.\u00a0Protecting Consumers, Patients, Passengers, and Students.\u00a0 (a) \u00a0Independent regulatory agencies are encouraged, as they deem appropriate, to consider using their full range of authorities to protect American consumers from fraud, discrimination, and threats to privacy and to address other risks that may arise from the use of AI, including risks to financial stability, and to consider rulemaking, as well as emphasizing or clarifying where existing regulations and guidance apply to AI, including clarifying the responsibility of regulated entities to conduct due diligence on and monitor any third-party AI services they use, and emphasizing or clarifying requirements and expectations related to the transparency of AI models and regulated entities\u2019 ability to explain their use of AI models.","passage: (b)\u00a0 To help ensure the safe, responsible deployment and use of AI in the healthcare, public-health, and human-services sectors:","passage: (i)\u00a0 \u00a0\u00a0Within 90 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an HHS AI Task Force that shall, within 365 days of its creation, develop a strategic plan that includes policies and frameworks \u2014 possibly including regulatory action, as appropriate \u2014 on responsible deployment and use of AI and AI-enabled technologies in the health and human services sector (including research and discovery, drug and device safety, healthcare delivery and financing, and public health), and identify appropriate guidance and","passage: resources to promote that deployment, including in the following areas:","passage: (A)\u00a0 development, maintenance, and use of predictive and generative AI-enabled technologies in healthcare delivery and financing \u2014 including quality measurement, performance improvement, program integrity, benefits administration, and patient experience \u2014 taking into account considerations such as appropriate human oversight of the application of AI-generated output;","passage: (B) \u00a0long-term safety and real-world performance monitoring of AI-enabled technologies in the health and human services sector, including clinically relevant or significant modifications and performance across population groups, with a means to communicate product updates to regulators, developers, and users;","passage: (C)\u00a0 incorporation of equity principles in AI-enabled technologies used in the health and human services sector, using disaggregated data on affected populations and representative population data sets when developing new models, monitoring algorithmic performance against discrimination and bias in existing models, and helping to identify and mitigate discrimination and bias in current systems;","passage: (D)\u00a0 incorporation of safety, privacy, and security standards into the software-development lifecycle for protection of personally identifiable information, including measures to address AI-enhanced cybersecurity threats in the health and human services sector;","passage: (E)\u00a0 development, maintenance, and availability of documentation to help users determine appropriate and safe uses of AI in local settings in the health and human services sector;","passage: (F)\u00a0 work to be done with State, local, Tribal, and territorial health and human services agencies to advance positive use cases and best practices for use of AI in local settings; and","passage: (G)\u00a0 identification of uses of AI to promote workplace efficiency and satisfaction in the health and human services sector, including reducing administrative burdens.","passage: (ii) \u00a0\u00a0Within 180 days of the date of this order, the Secretary of HHS shall direct HHS components, as the Secretary of HHS deems appropriate, to develop a strategy, in consultation with relevant agencies, to determine whether AI-enabled technologies in the health and human services sector maintain appropriate levels of quality, including, as appropriate, in the areas described in subsection (b)(i) of this section.\u00a0This work shall include the development of AI assurance policy \u2014 to evaluate important aspects of the performance of AI-enabled healthcare tools \u2014 and infrastructure needs for enabling pre-market assessment and post-market oversight of AI-enabled healthcare-technology algorithmic system performance against real-world data.","passage: (iii) \u00a0Within 180 days of the date of this order, the Secretary of HHS shall, in consultation with relevant agencies as the Secretary of HHS deems appropriate, consider appropriate actions to advance the prompt understanding of, and compliance with, Federal nondiscrimination laws by health and human services providers that receive Federal financial assistance, as well as how those laws relate to AI.\u00a0 Such actions may include:","passage: (A)\u00a0 convening and providing technical assistance to health and human services providers and payers about their obligations under Federal nondiscrimination and privacy laws as they relate to AI and the potential consequences of noncompliance; and","passage: (B)\u00a0 issuing guidance, or taking other action as appropriate, in response to any complaints or other reports of noncompliance with Federal nondiscrimination and privacy laws as they relate to AI.","passage: (iv) \u00a0\u00a0Within 365 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an AI safety program that, in partnership with voluntary federally listed Patient Safety Organizations:","passage: (A)\u00a0 establishes a common framework for approaches to identifying and capturing clinical errors resulting from AI deployed in healthcare settings as well as specifications for a central tracking repository for associated incidents that cause harm, including through bias or discrimination, to patients, caregivers, or other parties;","passage: (B)\u00a0 analyzes captured data and generated evidence to develop, wherever appropriate, recommendations, best practices, or other informal guidelines aimed at avoiding these harms; and","passage: (C)\u00a0 disseminates those recommendations, best practices, or other informal guidance to appropriate stakeholders, including healthcare providers.","passage: (v) \u00a0\u00a0\u00a0Within 365 days of the date of this order, the Secretary of HHS shall develop a strategy for regulating the use of AI or AI-enabled tools in drug-development processes.\u00a0 The strategy shall, at a minimum:","passage: (A)\u00a0 define the objectives, goals, and high-level principles required for appropriate regulation throughout each phase of drug development;","passage: (B)\u00a0 identify areas where future rulemaking, guidance, or additional statutory authority may be necessary to implement such a regulatory system;","passage: (C)\u00a0 identify the existing budget, resources, personnel, and potential for new public/private partnerships necessary for such a regulatory system; and","passage: (D) \u00a0consider risks identified by the actions undertaken to implement section 4 of this order.","passage: (c)\u00a0 To promote the safe and responsible development and use of AI in the transportation sector, in consultation with relevant agencies:","passage: (i)\u00a0 \u00a0\u00a0Within 30 days of the date of this order, the Secretary of Transportation shall direct the Nontraditional and Emerging Transportation Technology (NETT) Council to assess the need for information, technical assistance, and guidance regarding the use of AI in transportation.\u00a0 The Secretary of Transportation shall further direct the NETT Council, as part of any such efforts, to:","passage: (A)\u00a0 support existing and future initiatives to pilot transportation-related applications of AI, as they align with policy priorities articulated in the Department of Transportation\u2019s (DOT) Innovation Principles, including, as appropriate, through technical assistance and connecting stakeholders;","passage: (B)\u00a0 evaluate the outcomes of such pilot programs in order to assess when DOT, or other Federal or State agencies, have sufficient information to take regulatory actions, as appropriate, and recommend appropriate actions when that information is available; and","passage: (C)\u00a0 establish a new DOT Cross-Modal Executive Working Group, which will consist of members from different divisions of DOT and coordinate applicable work among these divisions, to solicit and use relevant input from appropriate stakeholders.","passage: (ii) \u00a0\u00a0Within 90 days of the date of this order, the Secretary of Transportation shall direct appropriate Federal Advisory Committees of the DOT to provide advice on the safe and responsible use of AI in transportation.\u00a0 The committees shall include the Advanced Aviation Advisory Committee, the Transforming Transportation Advisory Committee, and the Intelligent Transportation Systems Program Advisory Committee.","passage: (iii)\u00a0 Within 180 days of the date of this order, the Secretary of Transportation shall direct the Advanced Research Projects Agency-Infrastructure (ARPA-I) to explore the transportation-related opportunities and challenges of AI \u2014 including regarding software-defined AI enhancements impacting autonomous mobility ecosystems.\u00a0The Secretary of Transportation shall further encourage ARPA-I to prioritize the allocation of grants to those opportunities, as appropriate.\u00a0The work tasked to ARPA-I shall include soliciting input on these topics through a public consultation process, such as an RFI.","passage: (d)\u00a0 To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI.\u00a0These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate.\u00a0They shall also include the development of an \u201cAI toolkit\u201d for education leaders implementing recommendations from the Department of Education\u2019s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.","passage: (e)\u00a0 The Federal Communications Commission is encouraged to consider actions related to how AI will affect communications networks and consumers, including by:","passage: (i) \u00a0\u00a0\u00a0examining the potential for AI to improve spectrum management, increase the efficiency of non-Federal spectrum usage, and expand opportunities for the sharing of non-Federal spectrum;","passage: (ii) \u00a0\u00a0coordinating with the National Telecommunications and Information Administration to create opportunities for sharing spectrum between Federal and non-Federal spectrum operations;","passage: (iii)\u00a0 providing support for efforts to improve network security, resiliency, and interoperability using next-generation technologies that incorporate AI, including self-healing networks, 6G, and Open RAN; and","passage: (iv)\u00a0 \u00a0encouraging, including through rulemaking, efforts to combat unwanted robocalls and robotexts that are facilitated or exacerbated by AI and to deploy AI technologies that better serve consumers by blocking unwanted robocalls and robotexts.","passage: Sec.9.\u00a0Protecting Privacy.\u00a0 (a)\u00a0 To mitigate privacy risks potentially exacerbated by AI \u2014 including by AI\u2019s facilitation of the collection or use of information about individuals, or the making of inferences about individuals \u2014 the Director of OMB shall:","passage: (i) \u00a0\u00a0\u00a0evaluate and take steps to identify commercially available information (CAI) procured by agencies, particularly CAI that contains personally identifiable information and including CAI procured from data brokers and CAI procured and processed indirectly through vendors, in appropriate agency inventory and reporting processes (other than when it is used for the purposes of national security);","passage: (ii) \u00a0\u00a0evaluate, in consultation with the Federal Privacy Council and the Interagency Council on Statistical Policy, agency standards and procedures associated with the collection, processing, maintenance, use, sharing, dissemination, and disposition of CAI that contains personally identifiable information (other than when it is used for the purposes of national security) to inform potential guidance to agencies on ways to mitigate privacy and confidentiality risks from agencies\u2019 activities related to CAI;","passage: (iii)\u00a0 within 180 days of the date of this order, in consultation with the Attorney General, the Assistant to the President for Economic Policy, and the Director of OSTP, issue an RFI to inform potential revisions to guidance to agencies on implementing the privacy provisions of the E-Government Act of 2002 (Public\u00a0Law\u00a0107-347).\u00a0 The RFI shall seek feedback regarding how\u00a0privacy impact assessments\u00a0may be\u00a0more effective at mitigating privacy risks, including those that are further exacerbated by AI; and","passage: (iv) \u00a0\u00a0take such steps as are necessary and appropriate, consistent with applicable law, to support and advance the near-term actions and long-term strategy identified through the RFI process, including issuing new or updated guidance or RFIs or consulting other agencies or the Federal Privacy Council.","passage: (b)\u00a0 Within 365 days of the date of this order, to better enable agencies to use PETs to safeguard Americans\u2019 privacy from the potential threats exacerbated by AI, the Secretary of Commerce, acting through the Director of NIST, shall create guidelines for agencies to evaluate the efficacy of differential-privacy-guarantee protections, including for AI.\u00a0The guidelines shall, at a minimum, describe the significant factors that bear on differential-privacy safeguards and common risks to realizing differential privacy in practice.","passage: (c)\u00a0 To advance research, development, and implementation related to PETs:","passage: (i) \u00a0\u00a0\u00a0Within 120 days of the date of this order, the Director of NSF, in collaboration with the Secretary of Energy, shall fund the creation of a Research Coordination Network (RCN) dedicated to advancing privacy research and, in particular, the development, deployment, and scaling of PETs.\u00a0The RCN shall serve to enable privacy researchers to share information, coordinate and collaborate in research, and develop standards for the privacy-research community.","passage: (ii) \u00a0\u00a0Within 240 days of the date of this order, the Director of NSF shall engage with agencies to identify ongoing work and potential opportunities to incorporate PETs into their operations.\u00a0The Director of NSF shall, where feasible and appropriate, prioritize research \u2014 including efforts to translate research discoveries into practical applications \u2014 that encourage the adoption of leading-edge PETs solutions for agencies\u2019 use, including through research engagement through the RCN described in subsection (c)(i) of this section.","passage: (iii) \u00a0The Director of NSF shall use the results of the United States-United Kingdom PETs Prize Challenge to inform the approaches taken, and opportunities identified, for PETs research and adoption.","passage: Sec.10.\u00a0Advancing Federal Government Use of AI.","passage: 10.1.\u00a0Providing Guidance for AI Management.\u00a0 (a)\u00a0 To coordinate the use of AI across the Federal Government, within 60 days of the date of this order and on an ongoing basis as necessary, the Director of OMB shall convene and chair an interagency council to coordinate the development and use of AI in agencies\u2019 programs and operations, other than the use of AI in national security systems.\u00a0The Director of OSTP shall serve as Vice Chair for the interagency council.\u00a0The interagency council\u2019s membership shall include, at minimum, the heads of the agencies identified in 31 U.S.C. 901(b), the Director of National Intelligence, and other agencies as identified by the Chair.\u00a0 Until agencies designate their permanent Chief AI Officers consistent with the guidance described in subsection 10.1(b) of this section, they shall be represented on the interagency council by an appropriate official at the Assistant Secretary level or equivalent, as determined by the head of each agency.","passage: (b)\u00a0 To provide guidance on Federal Government use of AI, within 150 days of the date of this order and updated periodically thereafter, the Director of OMB, in coordination with the Director of OSTP, and in consultation with the interagency council established in subsection 10.1(a) of this section, shall issue guidance to agencies to strengthen the effective and appropriate use of AI, advance AI innovation, and manage risks from AI in the Federal Government.\u00a0 The Director of OMB\u2019s guidance shall specify, to the extent appropriate and consistent with applicable law:","passage: (i) \u00a0\u00a0\u00a0\u00a0the requirement to designate at each agency within 60 days of the issuance of the guidance a Chief Artificial Intelligence Officer who shall hold primary responsibility in their agency, in coordination with other responsible officials, for coordinating their agency\u2019s use of AI, promoting AI innovation in their agency, managing risks from their agency\u2019s use of AI, and carrying out the responsibilities described in section 8(c) of Executive Order 13960 of December 3, 2020 (Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government), and section 4(b) of Executive Order 14091;","passage: (ii) \u00a0\u00a0\u00a0the Chief Artificial Intelligence Officers\u2019 roles, responsibilities, seniority, position, and reporting structures;","passage: (iii) \u00a0\u00a0for the agencies identified in 31 U.S.C. 901(b), the creation of internal Artificial Intelligence Governance Boards, or other appropriate mechanisms, at each agency within 60 days of the issuance of the guidance to coordinate and govern AI issues through relevant senior leaders from across the agency;","passage: (iv) \u00a0\u00a0\u00a0required minimum risk-management practices for Government uses of AI that impact people\u2019s rights or safety, including, where appropriate, the following practices derived from OSTP\u2019s Blueprint for an AI Bill of Rights and the NIST AI Risk Management Framework: \u00a0conducting public consultation; assessing data quality; assessing and mitigating disparate impacts and algorithmic discrimination; providing notice of the use of AI; continuously monitoring and evaluating deployed AI; and granting human consideration and remedies for adverse decisions made using AI;","passage: (v) \u00a0\u00a0\u00a0\u00a0specific Federal Government uses of AI that are presumed by default to impact rights or safety;","passage: (vi) \u00a0\u00a0\u00a0recommendations to agencies to reduce barriers to the responsible use of AI, including barriers related to information technology infrastructure, data, workforce, budgetary restrictions, and cybersecurity processes;","passage: (vii) \u00a0\u00a0requirements that agencies identified in 31 U.S.C. 901(b) develop AI strategies and pursue high-impact AI use cases;","passage: (viii) \u00a0in consultation with the Secretary of Commerce, the Secretary of Homeland Security, and the heads of other appropriate agencies as determined by the Director of OMB, recommendations to agencies regarding:","passage: (A)\u00a0 external testing for AI, including AI red-teaming for generative AI, to be developed in coordination with the Cybersecurity and Infrastructure Security Agency;","passage: (B)\u00a0 testing and safeguards against discriminatory, misleading, inflammatory, unsafe, or deceptive outputs, as well as against producing child sexual abuse material and against producing non-consensual intimate imagery of real individuals (including intimate digital depictions of the body or body parts of an identifiable individual), for generative AI;","passage: (C)\u00a0 reasonable steps to watermark or otherwise label output from generative AI;","passage: (D)\u00a0 application of the mandatory minimum risk-management practices defined under subsection 10.1(b)(iv) of this section to procured AI;","passage: (E)\u00a0 independent evaluation of vendors\u2019 claims concerning both the effectiveness and risk mitigation of their AI offerings;","passage: (F)\u00a0 documentation and oversight of procured AI;","passage: (G)\u00a0 maximizing the value to agencies when relying on contractors to use and enrich Federal Government data for the purposes of AI development and operation;","passage: (H)\u00a0 provision of incentives for the continuous improvement of procured AI; and","passage: (I) \u00a0training on AI in accordance with the principles set out in this order and in other references related to AI listed herein; and","passage: (ix) \u00a0\u00a0\u00a0requirements for public reporting on compliance with this guidance.","passage: (c)\u00a0 To track agencies\u2019 AI progress, within 60 days of the issuance of the guidance established in subsection 10.1(b) of this section and updated periodically thereafter, the Director of OMB shall develop a method for agencies to track and assess their ability to adopt AI into their programs and operations, manage its risks, and comply with Federal policy on AI.\u00a0This method should draw on existing related efforts as appropriate and should address, as appropriate and consistent with applicable law, the practices, processes, and capabilities necessary for responsible AI adoption, training, and governance across, at a minimum, the areas of information technology infrastructure, data, workforce, leadership, and risk management.","passage: (d)\u00a0 To assist agencies in implementing the guidance to be established in subsection 10.1(b) of this section:","passage: (i) \u00a0\u00a0within 90 days of the issuance of the guidance, the Secretary of Commerce, acting through the Director of NIST, and in coordination with the Director of OMB and the Director of OSTP, shall develop guidelines, tools, and practices to support implementation of the minimum risk-management practices described in subsection 10.1(b)(iv) of this section; and","passage: (ii)\u00a0 within 180 days of the issuance of the guidance, the Director of OMB shall develop an initial means to ensure that agency contracts for the acquisition of AI systems and services align with the guidance described in subsection 10.1(b) of this section and advance the other aims identified in section 7224(d)(1) of the Advancing American AI Act (Public Law 117-263, div.G, title LXXII, subtitle B).","passage: (e)\u00a0 To improve transparency for agencies\u2019 use of AI, the Director of OMB shall, on an annual basis, issue instructions to agencies for the collection, reporting, and publication of agency AI use cases, pursuant to section 7225(a) of the Advancing American AI Act.\u00a0 Through these instructions, the Director shall, as appropriate, expand agencies\u2019 reporting on how they are managing risks from their AI use cases and update or replace the guidance originally established in section 5 of Executive Order 13960.","passage: (f)\u00a0 To advance the responsible and secure use of generative AI in the Federal Government:","passage: (i) \u00a0\u00a0\u00a0As generative AI products become widely available and common in online platforms, agencies are discouraged from imposing broad general bans or blocks on agency use of generative AI.\u00a0 Agencies should instead limit access, as necessary, to specific generative AI services based on specific risk assessments; establish guidelines and limitations on the appropriate use of generative AI; and, with appropriate safeguards in place, provide their personnel and programs with access to secure and reliable generative AI capabilities, at least for the purposes of experimentation and routine tasks that carry a low risk of impacting Americans\u2019 rights.\u00a0To protect Federal Government information, agencies are also encouraged to employ risk-management practices, such as training their staff on proper use, protection, dissemination, and disposition of Federal information; negotiating appropriate terms of service with vendors; implementing measures designed to ensure compliance with record-keeping, cybersecurity, confidentiality, privacy, and data protection requirements; and deploying other measures to prevent misuse of Federal Government information in generative AI.","passage: (ii) \u00a0\u00a0Within 90 days of the date of this order, the Administrator of General Services, in coordination with the Director of OMB, and in consultation with the Federal Secure Cloud Advisory Committee and other relevant agencies as the Administrator of General Services may deem appropriate, shall develop and issue a framework for prioritizing critical and emerging technologies offerings in the Federal Risk and Authorization Management Program authorization process, starting with generative AI offerings that have the primary purpose of providing large language model-based chat interfaces, code-generation and debugging tools, and associated application programming interfaces, as well as prompt-based image generators.\u00a0This framework shall apply for no less than 2 years from the date of its issuance.\u00a0Agency Chief Information Officers, Chief Information Security Officers, and authorizing officials are also encouraged to prioritize generative AI and other critical and emerging technologies in granting authorities for agency operation of information technology systems and any other applicable release or oversight processes, using continuous authorizations and approvals wherever feasible.","passage: (iii)\u00a0 Within 180 days of the date of this order, the Director of the Office of Personnel Management (OPM), in coordination with the Director of OMB, shall develop guidance on the use of generative AI for work by the Federal workforce.","passage: (g)\u00a0 Within 30 days of the date of this order, to increase agency investment in AI, the Technology Modernization Board shall consider, as it deems appropriate and consistent with applicable law, prioritizing funding for AI projects for the Technology Modernization Fund for a period of at least 1 year.\u00a0Agencies are encouraged to submit to the Technology Modernization Fund project funding proposals that include AI \u2014 and particularly generative AI \u2014 in service of mission delivery.","passage: (h)\u00a0 Within 180 days of the date of this order, to facilitate agencies\u2019 access to commercial AI capabilities, the Administrator of General Services, in coordination with the Director of OMB, and in collaboration with the Secretary of Defense, the Secretary of Homeland Security, the Director of National Intelligence, the Administrator of the National Aeronautics and Space Administration, and the head of any other agency identified by the Administrator of General Services, shall take steps consistent with applicable law to facilitate access to Federal Government-wide acquisition solutions for specified types of AI services and products, such as through the creation of a resource guide or other tools to assist the acquisition workforce.\u00a0Specified types of AI capabilities shall include generative AI and specialized computing infrastructure.","passage: (i)\u00a0 The initial means, instructions, and guidance issued pursuant to subsections 10.1(a)-(h) of this section shall not apply to AI when it is used as a component of a national security system, which shall be addressed by the proposed National Security Memorandum described in subsection 4.8 of this order.","passage: 10.2.\u00a0Increasing AI Talent in Government.\u00a0 (a)\u00a0 Within 45 days of the date of this order, to plan a national surge in AI talent in the Federal Government, the Director of OSTP and the Director of OMB, in consultation with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Assistant to the President and Domestic Policy Advisor, and the Assistant to the President and Director of the Gender Policy Council, shall identify priority mission areas for increased Federal Government AI talent, the types of talent that are highest priority to recruit and develop to ensure adequate implementation of this order and use of relevant enforcement and regulatory authorities to address AI risks, and accelerated hiring pathways.","passage: (b)\u00a0 Within 45 days of the date of this order, to coordinate rapid advances in the capacity of the Federal AI workforce, the Assistant to the President and Deputy Chief of Staff for Policy, in coordination with the Director of OSTP and the Director of OMB, and in consultation with the National Cyber Director, shall convene an AI and Technology Talent Task Force, which shall include the Director of OPM, the Director of the General Services Administration\u2019s Technology Transformation Services, a representative from the Chief Human Capital Officers Council, the Assistant to the President for Presidential Personnel, members of appropriate agency technology talent programs, a representative of the Chief Data Officer Council, and a representative of the interagency council convened under subsection 10.1(a) of this section.\u00a0The Task Force\u2019s purpose shall be to accelerate and track the hiring of AI and AI-enabling talent across the Federal Government, including through the following actions:","passage: (i) \u00a0\u00a0\u00a0within 180 days of the date of this order, tracking and reporting progress to the President on increasing AI capacity across the Federal Government, including submitting to the President a report and recommendations for further increasing capacity;","passage: (ii) \u00a0\u00a0identifying and circulating best practices for agencies to attract, hire, retain, train, and empower AI talent, including diversity, inclusion, and accessibility best practices, as well as to plan and budget adequately for AI workforce needs;","passage: (iii) \u00a0coordinating, in consultation with the Director of OPM, the use of fellowship programs and agency technology-talent programs and human-capital teams to build hiring capabilities, execute hires, and place AI talent to fill staffing gaps; and","passage: (iv) \u00a0\u00a0convening a cross-agency forum for ongoing collaboration between AI professionals to share best practices and improve retention.","passage: (c)\u00a0 Within 45 days of the date of this order, to advance existing Federal technology talent programs, the United States Digital Service, Presidential Innovation Fellowship, United States Digital Corps, OPM, and technology talent programs at agencies, with support from the AI and Technology Talent Task Force described in subsection 10.2(b) of this section, as appropriate and permitted by law, shall develop and begin to implement plans to support the rapid recruitment of individuals as part of a Federal Government-wide AI talent surge to accelerate the placement of key AI and AI-enabling talent in high-priority areas and to advance agencies\u2019 data and technology strategies.","passage: (d)\u00a0 To meet the critical hiring need for qualified personnel to execute the initiatives in this order, and to improve Federal hiring practices for AI talent, the Director of OPM, in consultation with the Director of OMB, shall:","passage: (i) \u00a0\u00a0\u00a0\u00a0within 60 days of the date of this order, conduct an evidence-based review on the need for hiring and workplace flexibility, including Federal Government-wide direct-hire authority for AI and related data-science and technical roles, and, where the Director of OPM finds such authority is appropriate, grant it; this review shall include the following job series at all General Schedule (GS) levels: \u00a0IT Specialist (2210), Computer Scientist (1550), Computer Engineer (0854), and Program Analyst (0343) focused on AI, and any subsequently developed job series derived from these job series;","passage: (ii) \u00a0\u00a0\u00a0within 60 days of the date of this order, consider authorizing the use of excepted service appointments under 5 C.F.R. 213.3102(i)(3) to address the need for hiring additional staff to implement directives of this order;","passage: (iii) \u00a0\u00a0within 90 days of the date of this order, coordinate a pooled-hiring action informed by subject-matter experts and using skills-based assessments to support the recruitment of AI talent across agencies;","passage: (iv) \u00a0\u00a0\u00a0within 120 days of the date of this order, as appropriate and permitted by law, issue guidance for agency application of existing pay flexibilities or incentive pay programs for AI, AI-enabling, and other key technical positions to facilitate appropriate use of current pay incentives;","passage: (v) \u00a0\u00a0\u00a0\u00a0within 180 days of the date of this order, establish guidance and policy on skills-based, Federal Government-wide hiring of AI, data, and technology talent in order to increase access to those with nontraditional academic backgrounds to Federal AI, data, and technology roles;","passage: (vi) \u00a0\u00a0\u00a0within 180 days of the date of this order, establish an interagency working group, staffed with both human-resources professionals and recruiting technical experts, to facilitate Federal Government-wide hiring of people with AI and other technical skills;","passage: (vii) \u00a0\u00a0within 180 days of the date of this order, review existing Executive Core Qualifications (ECQs) for Senior Executive Service (SES) positions informed by data and AI literacy competencies and, within 365 days of the date of this order, implement new ECQs as appropriate in the SES assessment process;","passage: (viii)\u00a0 within 180 days of the date of this order, complete a review of competencies for civil engineers (GS-0810 series) and, if applicable, other related occupations, and make recommendations for ensuring that adequate AI expertise and credentials in these occupations in the Federal Government reflect the increased use of AI in critical infrastructure; and","passage: (ix)\u00a0 \u00a0\u00a0work with the Security, Suitability, and Credentialing Performance Accountability Council to assess mechanisms to streamline and accelerate personnel-vetting requirements, as appropriate, to support AI and fields related to other critical and emerging technologies.","passage: (e)\u00a0 To expand the use of special authorities for AI hiring and retention, agencies shall use all appropriate hiring authorities, including Schedule A(r) excepted service hiring and direct-hire authority, as applicable and appropriate, to hire AI talent and AI-enabling talent rapidly.\u00a0In addition to participating in OPM-led pooled hiring actions, agencies shall collaborate, where appropriate, on agency-led pooled hiring under the Competitive Service Act of 2015 (Public Law 114-137) and other shared hiring.\u00a0Agencies shall also, where applicable, use existing incentives, pay-setting authorities, and other compensation flexibilities, similar to those used for cyber and information technology positions, for AI and data-science professionals, as well as plain-language job titles, to help recruit and retain these highly skilled professionals.\u00a0Agencies shall ensure that AI and other related talent needs (such as technology governance and privacy) are reflected in strategic workforce planning and budget formulation.","passage: (f)\u00a0 To facilitate the hiring of data scientists, the Chief Data Officer Council shall develop a position-description library for data scientists (job series 1560) and a hiring guide to support agencies in hiring data scientists.","passage: (g)\u00a0 To help train the Federal workforce on AI issues, the head of each agency shall implement \u2014 or increase the availability and use of \u2014 AI training and familiarization programs for employees, managers, and leadership in technology as well as relevant policy, managerial, procurement, regulatory, ethical, governance, and legal fields.\u00a0 Such training programs should, for example, empower Federal employees, managers, and leaders to develop and maintain an operating knowledge of emerging AI technologies to assess opportunities to use these technologies to enhance the delivery of services to the public, and to mitigate risks associated with these technologies.\u00a0Agencies that provide professional-development opportunities, grants, or funds for their staff should take appropriate steps to ensure that employees who do not serve in traditional technical roles, such as policy, managerial, procurement, or legal fields, are nonetheless eligible to receive funding for programs and courses that focus on AI, machine learning, data science, or other related subject areas.","passage: (h)\u00a0 Within 180 days of the date of this order, to address gaps in AI talent for national defense, the Secretary of Defense shall submit a report to the President through the Assistant to the President for","passage: National Security Affairs that includes:","passage: (i) \u00a0\u00a0\u00a0recommendations to address challenges in the Department of Defense\u2019s ability to hire certain noncitizens, including at the Science and Technology Reinvention Laboratories;","passage: (ii) \u00a0\u00a0recommendations to clarify and streamline processes for accessing classified information for certain noncitizens through Limited Access Authorization at Department of Defense laboratories;","passage: (iii)\u00a0 recommendations for the appropriate use of enlistment authority under 10 U.S.C. 504(b)(2) for experts in AI and other critical and emerging technologies; and","passage: (iv) \u00a0\u00a0recommendations for the Department of Defense and the Department of Homeland Security to work together to enhance the use of appropriate authorities for the retention of certain noncitizens of vital importance to national security by the Department of Defense and the Department of Homeland Security.","passage: ![](https://www.whitehouse.gov/wp-content/uploads/2023/10/image.gif \"Anchor\")","passage: Sec.11.\u00a0Strengthening American Leadership Abroad.\u00a0 (a)\u00a0 To strengthen United States leadership of global efforts to unlock AI\u2019s potential and meet its challenges, the Secretary of State, in coordination with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Director of OSTP, and the heads of other relevant agencies as appropriate, shall:","passage: (i) \u00a0\u00a0lead efforts outside of military and intelligence areas to expand engagements with international allies and partners in relevant bilateral, multilateral, and multi-stakeholder fora to advance those allies\u2019 and partners\u2019 understanding of existing and planned AI-related guidance and policies of the United States, as well as to enhance international collaboration; and","passage: (ii) \u00a0lead efforts to establish a strong international framework for managing the risks and harnessing the benefits of AI, including by encouraging international allies and partners to support voluntary commitments similar to those that United States companies have made in pursuit of these objectives and coordinating the activities directed by subsections (b), (c), (d), and (e) of this section, and to develop common regulatory and other accountability principles for foreign nations, including to manage the risk that AI systems pose.","passage: (b)\u00a0 To advance responsible global technical standards for AI development and use outside of military and intelligence areas, the Secretary of Commerce, in coordination with the Secretary of State and the heads of other relevant agencies as appropriate, shall lead preparations for a coordinated effort with key international allies and partners and with standards development organizations, to drive the development and implementation of AI-related consensus standards, cooperation and coordination, and information sharing.\u00a0In particular, the Secretary of Commerce shall:","passage: (i)\u00a0 \u00a0\u00a0within 270 days of the date of this order, establish a plan for global engagement on promoting and developing AI standards, with lines of effort that may include:","passage: (A) \u00a0AI nomenclature and terminology;","passage: (B)\u00a0 best practices regarding data capture, processing, protection, privacy, confidentiality, handling, and analysis;","passage: (C)\u00a0 trustworthiness, verification, and assurance of AI systems; and","passage: (D) \u00a0AI risk management;","passage: (ii)\u00a0 \u00a0within 180 days of the date the plan is established, submit a report to the President on priority actions taken pursuant to the plan; and","passage: (iii)\u00a0 ensure that such efforts are guided by principles set out in the NIST AI Risk Management Framework and United States Government National Standards Strategy for Critical and Emerging Technology.","passage: (c)\u00a0 Within 365 days of the date of this order, to promote safe, responsible, and rights-affirming development and deployment of AI abroad:","passage: (i) \u00a0\u00a0The Secretary of State and the Administrator of the United States Agency for International Development, in coordination with the Secretary of Commerce, acting through the director of NIST, shall publish an AI in Global Development Playbook that incorporates the AI Risk Management Framework\u2019s principles, guidelines, and best practices into the social, technical, economic, governance, human rights, and security conditions of contexts beyond United States borders.\u00a0As part of this work, the Secretary of State and the Administrator of the United States Agency for International Development shall draw on lessons learned from programmatic uses of AI in global development.","passage: (ii)\u00a0 The Secretary of State and the Administrator of the United States Agency for International Development, in collaboration with the Secretary of Energy and the Director of NSF, shall develop a Global AI Research Agenda to guide the objectives and implementation of AI-related research in contexts beyond United States borders.\u00a0The Agenda shall:","passage: (A)\u00a0 include principles, guidelines, priorities, and best practices aimed at ensuring the safe, responsible, beneficial, and sustainable global development and adoption of AI; and","passage: (B)\u00a0 address AI\u2019s labor-market implications across international contexts, including by recommending risk mitigations.","passage: (d) \u00a0To address cross-border and global AI risks to critical infrastructure, the Secretary of Homeland Security, in coordination with the Secretary of State, and in consultation with the heads of other relevant agencies as the Secretary of Homeland Security deems appropriate, shall lead efforts with international allies and partners to enhance cooperation to prevent, respond to, and recover from potential critical infrastructure disruptions resulting from incorporation of AI into critical infrastructure systems or malicious use of AI.","passage: (i) \u00a0\u00a0Within 270 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of State, shall develop a plan for multilateral engagements to encourage the adoption of the AI safety and security guidelines for use by critical infrastructure owners and operators developed in section 4.3(a) of this order.","passage: (ii) \u00a0Within 180 days of establishing the plan described in subsection (d)(i) of this section, the Secretary of Homeland Security shall submit a report to the President on priority actions to mitigate cross-border risks to critical United States infrastructure.","passage: Sec.12.\u00a0Implementation.\u00a0(a)\u00a0 There is established, within the Executive Office of the President, the White House Artificial Intelligence Council (White House AI Council).\u00a0The function of the White House AI Council is to coordinate the activities of agencies across the Federal Government to ensure the effective formulation, development, communication, industry engagement related to, and timely implementation of AI-related policies, including policies set forth in this order.","passage: (b)\u00a0 The Assistant to the President and Deputy Chief of Staff for Policy shall serve as Chair of the White House AI Council.","passage: (c) \u00a0In addition to the Chair, the White House AI Council shall consist of the following members, or their designees:","passage: (i) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of State;","passage: (ii) \u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of the Treasury;","passage: (iii) \u00a0\u00a0\u00a0\u00a0the Secretary of Defense;","passage: (iv) \u00a0\u00a0\u00a0\u00a0\u00a0the Attorney General;","passage: (v) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of Agriculture;","passage: (vi) \u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of Commerce;","passage: (vii) \u00a0\u00a0\u00a0\u00a0the Secretary of Labor;","passage: (viii) \u00a0\u00a0\u00a0the Secretary of HHS;","passage: (ix) \u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of Housing and Urban Development;","passage: (x) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of Transportation;","passage: (xi) \u00a0\u00a0\u00a0\u00a0\u00a0the Secretary of Energy;","passage: (xii) \u00a0\u00a0\u00a0\u00a0the Secretary of Education;","passage: (xiii) \u00a0\u00a0\u00a0the Secretary of Veterans Affairs;","passage: (xiv) \u00a0\u00a0\u00a0\u00a0the Secretary of Homeland Security;","passage: (xv) \u00a0\u00a0\u00a0\u00a0\u00a0the Administrator of the Small Business Administration;","passage: (xvi)\u00a0\u00a0 \u00a0\u00a0the Administrator of the United States Agency for International Development;","passage: (xvii)\u00a0 \u00a0\u00a0the Director of National Intelligence;","passage: (xviii) \u00a0\u00a0the Director of NSF;","passage: (xix) \u00a0\u00a0\u00a0\u00a0the Director of OMB;","passage: (xx)\u00a0\u00a0 \u00a0\u00a0\u00a0the Director of OSTP;","passage: (xxi)\u00a0 \u00a0\u00a0\u00a0the Assistant to the President for National Security Affairs;","passage: (xxii)\u00a0 \u00a0\u00a0the Assistant to the President for Economic Policy;","passage: (xxiii) \u00a0\u00a0the Assistant to the President and Domestic Policy Advisor;","passage: (xxiv)\u00a0 \u00a0\u00a0the Assistant to the President and Chief of Staff to the Vice President;","passage: (xxv)\u00a0 \u00a0\u00a0\u00a0the Assistant to the President and Director of the Gender Policy Council;","passage: (xxvi) \u00a0\u00a0\u00a0the Chairman of the Council of Economic Advisers;","passage: (xxvii) \u00a0\u00a0the National Cyber Director;","passage: (xxviii) \u00a0the Chairman of the Joint Chiefs of Staff; and","passage: (xxix)\u00a0 \u00a0\u00a0the heads of such other agencies, independent regulatory agencies, and executive offices as the Chair may from time to time designate or invite to participate.","passage: (d)\u00a0 The Chair may create and coordinate subgroups consisting of White House AI Council members or their designees, as appropriate.","passage: Sec.13.\u00a0General Provisions.\u00a0 (a)\u00a0 Nothing in this order shall be construed to impair or otherwise affect:","passage: (i)\u00a0 \u00a0the authority granted by law to an executive department or agency, or the head thereof; or","passage: (ii)\u00a0 the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals.","passage: (b)\u00a0 This order shall be implemented consistent with applicable law and subject to the availability of appropriations.","passage: (c)\u00a0 This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.","passage: JOSEPH R. BIDEN JR.","passage: THE WHITE HOUSE,","passage: October 30, 2023.","passage: # Directive on Automated Decision-Making","passage: ## 1.Effective date","passage: - 1.1","passage: This directive takes effect on\u00a0April 1, 2019, with compliance required by no later than\u00a0April 1, 2020.","passage: - 1.2","passage: This directive applies to all automated decision systems developed or procured after\u00a0April 1, 2020.However,","passage: - 1.2.1","passage: existing systems developed or procured prior to\u00a0April 25, 2023\u00a0will have until\u00a0April 25, 2024\u00a0to fully transition to the requirements in subsections 6.2.3, 6.3.1, 6.3.4, 6.3.5 and 6.3.6 in this directive;","passage: - 1.2.2","passage: new systems developed or procured after\u00a0April 25, 2023\u00a0will have until\u00a0October 25, 2023\u00a0to meet the requirements in this directive.","passage: - 1.3","passage: This directive will be reviewed every two years, and as determined by the Chief Information Officer of Canada.","passage: ## 2.Authorities","passage: - 2.1","passage: This directive is issued pursuant to the same authority indicated in section 2 of the\u00a0[_Policy on Service and Digital_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32603).","passage: ## 3.Definitions","passage: - 3.1","passage: Definitions to be used in the interpretation of this directive are listed in\u00a0[Appendix A](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592&amp;section=html#appA).","passage: ## 4.Objectives and expected results","passage: - 4.1","passage: The objective of this directive is to ensure that automated decision systems are deployed in a manner that reduces risks to clients, federal institutions and Canadian society, and leads to more efficient, accurate, consistent and interpretable decisions made pursuant to Canadian law.","passage: - 4.2","passage: The expected results of this directive are as follows:","passage: - 4.2.1","passage: Decisions made by federal institutions are data-driven, responsible and comply with procedural fairness and due process requirements.","passage: - 4.2.2","passage: Impacts of algorithms on administrative decisions are assessed and negative outcomes are reduced, when encountered.","passage: - 4.2.3","passage: Data and information on the use of automated decision systems in federal institutions are made available to the public, where appropriate.","passage: ## 5.Scope","passage: - 5.1","passage: This directive applies to any system, tool, or statistical model used to make an administrative decision or a related assessment about a client.","passage: - 5.2","passage: This directive applies only to automated decision systems in production and excludes systems operating in test environments.","passage: ## 6.Requirements","passage: The Assistant Deputy Minister responsible for the program using the automated decision system, or any other person named by the Deputy Head, is responsible for:","passage: ### 6.1 Algorithmic Impact Assessment","passage: - 6.1.1","passage: Completing and releasing the final results of an\u00a0[Algorithmic Impact Assessment](https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/algorithmic-impact-assessment.html)\u00a0prior to the production of any automated decision system.","passage: - 6.1.2","passage: Applying the relevant requirements prescribed in Appendix C as determined by the Algorithmic Impact Assessment.","passage: - 6.1.3","passage: Reviewing and updating the Algorithmic Impact Assessment on a scheduled basis, including when the functionality or scope of the automated decision system changes.","passage: - 6.1.4","passage: Releasing the final results of the Algorithmic Impact Assessment in an accessible format via Government of Canada websites and any other services designated by the Treasury Board of Canada Secretariat pursuant to the\u00a0[_Directive on Open Government_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=28108).","passage: ### 6.2 Transparency","passage: #### Providing notice before decisions","passage: - 6.2.1","passage: Providing notice through all service delivery channels in use that the decision rendered will be undertaken in whole or in part by an automated decision system, as prescribed in Appendix C.","passage: - 6.2.2","passage: Providing notices prominently and in plain language, pursuant to the\u00a0[Canada.ca Content Style Guide](https://www.canada.ca/en/treasury-board-secretariat/services/government-communications/canada-content-style-guide.html#toc5).","passage: #### Providing explanations after decisions","passage: - 6.2.3","passage: Providing a meaningful explanation to affected individuals of how and why the decision was made, as prescribed in Appendix C.","passage: #### Access to components","passage: - 6.2.4","passage: Determining the appropriate licence for software components, including consideration of open source software in accordance with the measures specified in the\u00a0[_Government of Canada Enterprise Architecture Framework_](https://www.canada.ca/en/government/system/digital-government/policies-standards/government-canada-enterprise-architecture-framework.html).","passage: - 6.2.5","passage: If using a proprietary licence, ensuring that:","passage: - 6.2.5.1","passage: All released versions of proprietary software components used for automated decision systems are delivered to, and safeguarded by, the department.","passage: - 6.2.5.2","passage: The Government of Canada retains the right to access and test automated decision systems, including all released versions of proprietary software components, in case it is necessary for a specific audit, investigation, inspection, examination, enforcement action, or judicial proceeding, subject to safeguards against unauthorized disclosure.","passage: - 6.2.5.3","passage: As part of this access, the Government of Canada retains the right to authorize external parties to review and audit these components as necessary.","passage: #### Release of source code","passage: - 6.2.6","passage: Releasing custom source code owned by the Government of Canada in accordance with the measures specified in the\u00a0[_Government of Canada Enterprise Architecture Framework_](https://www.canada.ca/en/government/system/digital-government/policies-standards/government-canada-enterprise-architecture-framework.html), unless:","passage: - 6.2.6.1","passage: the source code is processing data classified as Secret, Top Secret or Protected C; or","passage: - 6.2.6.2","passage: disclosure would otherwise be exempted or excluded under the\u00a0_Access to Information Act_, if the\u00a0_Access to Information Act_\u00a0were to apply.","passage: - 6.2.7","passage: Determining the appropriate access restrictions to the released source code.","passage: #### Documenting decisions","passage: - 6.2.8","passage: Documenting the decisions of automated decision systems in accordance with the\u00a0_[Directive on Service and Digital](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32601)_, and in support of the monitoring (6.3.2), data governance (6.3.4) and reporting requirements (6.5.1).","passage: ### 6.3 Quality assurance","passage: #### Testing and monitoring outcomes","passage: - 6.3.1","passage: Before launching into production, developing processes so that the data and information used by the automated decision system, as well as the system\u2019s underlying model, are tested for unintended biases and other factors that may unfairly impact the outcomes.","passage: - 6.3.2","passage: Developing processes to monitor the outcomes of the automated decision system to safeguard against unintentional outcomes and to verify compliance with institutional and program legislation, as well as this directive, on a scheduled basis.","passage: #### Data quality","passage: - 6.3.3","passage: Validating that the data collected for, and used by, the automated decision system is relevant, accurate, up-to-date, and in accordance with the\u00a0[_Policy on Service and Digital_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32603)\u00a0and the\u00a0[_Privacy Act_](https://laws-lois.justice.gc.ca/eng/ACTS/P-21/).","passage: #### Data governance","passage: - 6.3.4Establishing measures to ensure that data used and generated by the automated decision system are traceable, protected and accessed appropriately, and lawfully collected, used, retained and disposed of in accordance with the\u00a0[_Directive on Service and Digital_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32601),\u00a0[_Directive on Privacy Practices_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=18309), and\u00a0[_Directive on Security Management_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32611).","passage: #### Peer review","passage: - 6.3.5","passage: Consulting the appropriate qualified experts to review the automated decision system and publishing the complete review or a plain language summary of the findings prior to the system\u2019s production, as prescribed in Appendix C.","passage: #### Gender-based Analysis Plus","passage: - 6.3.6","passage: Completing a Gender-based Analysis Plus during the development or modification of the automated decision system, as prescribed in Appendix C.","passage: #### Employee training","passage: - 6.3.7","passage: Providing adequate employee training in the design, function, and implementation of the automated decision system to be able to review, explain and oversee its operations, as prescribed in Appendix C.","passage: #### IT and business continuity management","passage: - 6.3.8","passage: Establishing strategies, plans and/or measures to support IT and business continuity management, as prescribed in Appendix C and in accordance with the\u00a0[_Directive on Security Management_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32611).","passage: #### Security","passage: - 6.3.9","passage: Conducting risk assessments during the development of the automated decision system and establishing appropriate safeguards, in accordance with the\u00a0[_Policy on Government Security_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=16578).","passage: #### Legal","passage: - 6.3.10","passage: Consulting with the institution\u2019s legal services from the concept stage of an automation project to ensure that the use of the automated decision system is compliant with applicable legal requirements.","passage: #### Ensuring human intervention","passage: - 6.3.11","passage: Ensuring that the automated decision system allows for human intervention, when appropriate, as prescribed in Appendix C.","passage: - 6.3.12","passage: Obtaining the appropriate level of approvals prior to the production of an automated decision system, as prescribed in Appendix C.","passage: ### 6.4 Recourse","passage: - 6.4.1","passage: Providing clients with any applicable recourse options that are available to them to challenge the administrative decision.","passage: ### 6.5 Reporting","passage: - 6.5.1","passage: Publishing information on the effectiveness and efficiency of the automated decision system in meeting program objectives on a website or service designated by the Treasury Board of Canada Secretariat.","passage: ## 7.Consequences","passage: - 7.1","passage: Consequences of non-compliance with this directive can include any measure allowed by the\u00a0[_Financial Administration Act_](https://laws-lois.justice.gc.ca/eng/acts/F-11/page-1.html)\u00a0that the Treasury Board would determine as appropriate and acceptable in the circumstances.","passage: - 7.2","passage: For an outline of the consequences of non\u2011compliance, refer to the\u00a0[_Framework for the Management of Compliance_](http://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=17151), Appendix C: Consequences for Institutions and Appendix D: Consequences for Individuals.","passage: ## 8.Roles and responsibilities of Treasury Board of Canada Secretariat","passage: Subject to the necessary delegations, the Chief Information Officer of Canada is responsible for:","passage: - 8.1","passage: Providing government-wide guidance on the use of automated decision systems.","passage: - 8.2","passage: Developing and maintaining the Algorithmic Impact Assessment and any supporting documentation.","passage: - 8.3","passage: Communicating and engaging government-wide and with partners in other jurisdictions and sectors to develop common strategies, approaches, and processes to support the responsible use of automated decision systems.","passage: ## 9.Application","passage: - 9.1","passage: This directive applies to all institutions subject to the\u00a0[_Policy on Service and Digital_](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32603), unless excluded by specific acts, regulations or Orders-in-Council;","passage: - 9.1.1","passage: Agents of Parliament are excluded from this directive, including the:","passage: - Office of the Auditor General of Canada,","passage: - Office of the Chief Electoral Officer,","passage: - Office of the Commissioner of Lobbying of Canada,","passage: - Office of the Commissioner of Official Languages,","passage: - Office of the Information Commissioner of Canada,","passage: - Office of the Privacy Commissioner of Canada, and","passage: - Office of the Public Sector Integrity Commissioner of Canada.","passage: - 9.2","passage: Agencies, Crown Corporations, or Agents of Parliament may enter into Specific Agreements with the Treasury Board of Canada Secretariat to adopt the requirements of this directive and apply them to their organization, as required.","passage: ## 10.References","passage: - 10.1","passage: **Legislation**","passage: - [_Financial Administration Act_](http://laws-lois.justice.gc.ca/eng/acts/F-11/)","passage: - [_Access to Information Act_](http://laws-lois.justice.gc.ca/eng/acts/A-1/)","passage: - [_Canadian Human Rights Act_](http://laws-lois.justice.gc.ca/eng/acts/h-6/)","passage: - [_Privacy Act_](http://laws-lois.justice.gc.ca/eng/acts/P-21/)","passage: - [_Security of Information Act_](http://laws-lois.justice.gc.ca/eng/acts/O-5/)","passage: - [_Accessible Canada Act_](https://www.laws-lois.justice.gc.ca/eng/acts/A-0.6/)","passage: - 10.2","passage: **Related policy instruments**","passage: - [_Policy on Access to Information_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=12453)","passage: - [_Policy on Service and Digital_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32603)","passage: - [_Policy on Government Security_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=16578)","passage: - [_Policy on Privacy Protection_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=12510)","passage: - [_Policy on People Management_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32621)","passage: - [_Directive on Open Government_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=28108)","passage: - [_Standard on Security Screening_](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=28115)","passage: ## 11.Enquiries","passage: - 11.1","passage: For interpretation of any aspect of this directive, contact\u00a0[Treasury Board of Canada Secretariat Public Enquiries](https://www.canada.ca/en/treasury-board-secretariat/corporate/contact.html).","passage: - 11.2","passage: Individuals from federal institutions may contact\u00a0[ai-ia@tbs-sct.gc.ca](mailto:ai-ia@tbs-sct.gc.ca)\u00a0for any questions regarding this directive, including the Algorithmic Impact Assessment.","passage: ## Appendix A - Definitions","passage: administrative decision","passage: Any decision that is made by an authorized official of an institution as identified in section 9 of this directive pursuant to powers conferred by an Act of Parliament or an order made pursuant to a prerogative of the Crown that affects legal rights, privileges or interests.","passage: algorithmic impact assessment","passage: A framework to help institutions better understand and reduce the risks associated with automated decision systems and to provide the appropriate governance, oversight and reporting/audit requirements that best match the type of application being designed.","passage: artificial intelligence","passage: Information technology that performs tasks that would ordinarily require biological brainpower to accomplish, such as making sense of spoken language, learning behaviours or solving problems.","passage: automated decision system","passage: Any technology that either assists or replaces the judgment of human decision-makers.These systems draw from fields like statistics, linguistics and computer science, and use techniques such as rules-based systems, regression, predictive analytics, machine learning, deep learning, and neural nets.","passage: procedural fairness","passage: A guiding principle of governmental and quasi-judicial decision-making.The degree of procedural fairness that the law requires for any given decision-making process increases or decreases with the significance of that decision and its impact on rights and interests.","passage: source code","passage: A computer program in its original, human-readable programming language, before translation into object code usually by a compiler or an interpreter.It consists of algorithms and computer instructions, and may include a developer\u2019s comments.","passage: test environment","passage: An environment containing hardware, instrumentation, simulators, software tools, and other support elements needed to conduct a test.","passage: ## Appendix B - Impact Assessment Levels","passage: |Level|Description|","passage: |---|---|","passage: |I|The decision will likely have little to no impact on:&lt;br&gt;&lt;br&gt;- the rights of individuals or communities;&lt;br&gt;- the equality, dignity, privacy, and autonomy of individuals;&lt;br&gt;- the health or well-being of individuals or communities;&lt;br&gt;- the economic interests of individuals, entities, or communities;&lt;br&gt;- the ongoing sustainability of an ecosystem.&lt;br&gt;&lt;br&gt;Level\u00a0I\u00a0decisions will often lead to impacts that are reversible and brief.|","passage: |II|The decision will likely have moderate impacts on:&lt;br&gt;&lt;br&gt;- the rights of individuals or communities;&lt;br&gt;- the equality, dignity, privacy, and autonomy of individuals;&lt;br&gt;- the health or well-being of individuals or communities;&lt;br&gt;- the economic interests of individuals, entities, or communities;&lt;br&gt;- the ongoing sustainability of an ecosystem.&lt;br&gt;&lt;br&gt;Level\u00a0II\u00a0decisions will often lead to impacts that are likely reversible and short-term.|","passage: |III|The decision will likely have high impacts on:&lt;br&gt;&lt;br&gt;- the rights of individuals or communities;&lt;br&gt;- the equality, dignity, privacy, and autonomy of individuals;&lt;br&gt;- the health or well-being of individuals or communities;&lt;br&gt;- the economic interests of individuals, entities, or communities;&lt;br&gt;- the ongoing sustainability of an ecosystem.&lt;br&gt;&lt;br&gt;Level\u00a0III\u00a0decisions will often lead to impacts that can be difficult to reverse and are ongoing.|","passage: |IV|The decision will likely have very high impacts on:&lt;br&gt;&lt;br&gt;- the rights of individuals or communities;&lt;br&gt;- the equality, dignity, privacy, and autonomy of individuals;&lt;br&gt;- the health or well-being of individuals or communities;&lt;br&gt;- the economic interests of individuals, entities, or communities;&lt;br&gt;- the ongoing sustainability of an ecosystem.&lt;br&gt;&lt;br&gt;Level\u00a0IV\u00a0decisions will often lead to impacts that are irreversible and perpetual.|","passage: ## Appendix C - Impact Level Requirements","passage: |Requirement|Level\u00a0I|Level\u00a0II|Level\u00a0III|Level\u00a0IV|","passage: |---|---|---|---|---|","passage: |Peer review  &lt;br&gt;(section 6.3.5)|None|Consult at least one of the following experts and publish the complete review or a plain language summary of the findings on a Government of Canada website:&lt;br&gt;&lt;br&gt;Qualified expert from a federal, provincial, territorial or municipal government institution&lt;br&gt;&lt;br&gt;Qualified members of faculty of a post-secondary institution&lt;br&gt;&lt;br&gt;Qualified researchers from a relevant non-governmental organization&lt;br&gt;&lt;br&gt;Contracted third-party vendor with a relevant specialization&lt;br&gt;&lt;br&gt;A data and automation advisory board specified by Treasury Board of Canada Secretariat&lt;br&gt;&lt;br&gt;**OR**:&lt;br&gt;&lt;br&gt;Publish specifications of the automated decision system in a peer-reviewed journal.Where access to the published review is restricted, ensure that a plain language summary of the findings is openly available.|   |Consult at least two of the following experts and publish the complete review or a plain language summary of the findings on a Government of Canada website:&lt;br&gt;&lt;br&gt;Qualified experts from the National Research Council of Canada, Statistics Canada, or the Communications Security Establishment&lt;br&gt;&lt;br&gt;Qualified members of faculty of a post-secondary institution&lt;br&gt;&lt;br&gt;Qualified researchers from a relevant non-governmental organization&lt;br&gt;&lt;br&gt;Contracted third-party vendor with a relevant specialization&lt;br&gt;&lt;br&gt;A data and automation advisory board specified by Treasury Board of Canada Secretariat&lt;br&gt;&lt;br&gt;**OR:**&lt;br&gt;&lt;br&gt;Publish specifications of the automated decision system in a peer-reviewed journal.Where access to the published review is restricted, ensure that a plain language summary of the findings is openly available.|","passage: |Gender-based Analysis Plus  &lt;br&gt;(section 6.3.6)|None|Ensure that the Gender-based Analysis Plus addresses the following issues:&lt;br&gt;&lt;br&gt;- impacts of the automation project (including the system, data and decision) on gender and/or other identity factors;&lt;br&gt;- planned or existing measures to address risks identified through the Gender-based Analysis Plus.|   |   |","passage: |Notice  &lt;br&gt;(sections 6.2.1\u20136.2.2)|None|Plain language notice posted through all service delivery channels in use (Internet, in person, mail or telephone).|Plain language notice posted through all service delivery channels in use (Internet, in person, mail or telephone).In addition, publish documentation on relevant websites about the automated decision system, in plain language, describing:&lt;br&gt;&lt;br&gt;- how the components work;&lt;br&gt;- how it supports the administrative decision;&lt;br&gt;- results of any reviews or audits; and&lt;br&gt;- a description of the training data, or a link to the anonymized training data if this data is publicly available.|   |","passage: |Human-in-the-loop for decisions  &lt;br&gt;(section 6.3.11)|Decisions may be rendered without direct human involvement.|   |Decisions cannot be made without having specific human intervention points during the decision-making process; and&lt;br&gt;&lt;br&gt;The final decision must be made by a human.|   |","passage: |Explanation  &lt;br&gt;(section 6.3.2)|In addition to any applicable legal requirement, ensure that a meaningful explanation is published for common decision results.The explanation must provide a general description of:&lt;br&gt;&lt;br&gt;- the role of the system in the decision-making process;&lt;br&gt;- input data, its source and method of collection;&lt;br&gt;- the criteria used to evaluate input data and the operations applied to process it;&lt;br&gt;- the output produced by the system and any relevant information needed to interpret it in the context of the administrative decision;  &lt;br&gt;    and&lt;br&gt;- the principal factors behind a decision.&lt;br&gt;&lt;br&gt;Explanations must also inform clients of relevant recourse options, where appropriate.&lt;br&gt;&lt;br&gt;Descriptions must be made available in plain language through the Algorithmic Impact Assessment and discoverable via a departmental website.|In addition to any applicable legal requirement, ensure that a meaningful explanation is provided to the client with any decision that results in the denial of a benefit or service, or involves a regulatory action.The explanation must inform the client in plain language of:&lt;br&gt;&lt;br&gt;- the role of the system in the decision-making process;&lt;br&gt;- the training and client data, their source, and method of collection, as applicable;&lt;br&gt;- the criteria used to evaluate client data and the operations applied to process it;&lt;br&gt;- the output produced by the system and any relevant information needed to interpret it in the context of the administrative decision; and&lt;br&gt;- a justification of the administrative decision, including the principal factors that led to it.&lt;br&gt;&lt;br&gt;Explanations must also inform clients of relevant recourse options, where appropriate.&lt;br&gt;&lt;br&gt;A general description of these elements must also be made available through the Algorithmic Impact Assessment and discoverable via a departmental website.|   |   |","passage: |Training  &lt;br&gt;(section 6.3.7)|None|Documentation on the design and functionality of the system.|Documentation on the design and functionality of the system.&lt;br&gt;&lt;br&gt;Training courses must be completed.|Documentation on the design and functionality of the system.&lt;br&gt;&lt;br&gt;Recurring training courses.&lt;br&gt;&lt;br&gt;A means to verify that training has been completed.|","passage: |IT and business continuity management  &lt;br&gt;(section 6.3.8)|None|   |Ensure that system recovery strategies, business continuity plans, and other relevant security controls are established in coordination with designated officials should the automated decision system be unavailable.|   |","passage: |Approval for the system to operate  &lt;br&gt;(section 6.3.12)|None|None|Deputy Head|Treasury Board|","passage: # Hiroshima Process International Code of Conduct for Organizations Developing Advanced AI Systems","passage: On the basis of the International Guiding Principles for Organizations Developing Advanced AI systems, the International Code of Conduct for Organizations Developing Advanced AI Systems aims to promote safe, secure, and trustworthy AI worldwide and will provide voluntary guidance for actions by organizations developing the most advanced AI systems, including the most advanced foundation models and generative AI systems (henceforth \"advanced AI systems\").","passage: Organizations should follow these actions in line with a risk-based approach.","passage: Organizations that may endorse this Code of Conduct may include, among others, entities from academia, civil society, the private sector, and/or the public sector.","passage: This non-exhaustive list of actions is discussed and elaborated as a living document to build on the existing OECD AI Principles in response to the recent developments in advanced AI systems and is meant to help seize the benefits and address the risks and challenges brought by these technologies.Organizations should apply these actions to all stages of the lifecycle to cover, when and as applicable, the design, development, deployment and use of advanced AI systems.","passage: This document will be reviewed and updated as necessary, including through ongoing inclusive multistakeholder consultations, in order to ensure it remains fit for purpose and responsive to this rapidly evolving technology.","passage: Different jurisdictions may take their own unique approaches to implementing these actions in different ways.","passage: We call on organizations in consultation with other relevant stakeholders to follow these actions, in line with a risk-based approach, while governments develop more enduring and/or detailed governance and regulatory approaches.We also commit to develop proposals, in consultation with the OECD, GPAI and other stakeholders, to introduce monitoring tools and mechanisms to help organizations stay accountable for the implementation of these actions.We encourage organizations to support the development of effective monitoring mechanisms, which we may explore to develop, by contributing best practices.","passage: In addition, we encourage organizations to set up internal AI governance structures and policies, including self-assessment mechanisms, to facilitate a responsible and accountable approach to implementation of these actions and in AI development.","passage: While harnessing the opportunities of innovation, organizations should respect the rule of law, human rights, due process, diversity, fairness and non-discrimination, democracy, and human-centricity, in the design, development and deployment of advanced AI systems.","passage: Organizations should not develop or deploy advanced AI systems in ways that undermine democratic values, are particularly harmful to individuals or communities, facilitate terrorism, promote criminal misuse, or pose substantial risks to safety, security and human rights, and are thus not acceptable.","passage: States must abide by their obligations under international human rights law to ensure that human rights are fully respected and protected, while private sector activities should be in line with international frameworks such as the United Nations Guiding Principles on Business and Human Rights and the OECD Guidelines for Multinational Enterprises.","passage: Specifically, we call on organizations to abide by the following actions, in a manner that is commensurate to the risks:","passage: **1 Take appropriate measures throughout the development of advanced AI systems, including prior to and throughout their deployment and placement on the market, to identify, evaluate, and mitigate risks across the AI lifecycle.**","passage: This includes employing diverse internal and independent external testing measures, through a combination of methods for evaluations, such as red-teaming, and implementing appropriate mitigation to address identified risks and vulnerabilities.Testing and mitigation measures, should, for example, seek to ensure the trustworthiness, safety and security of systems throughout their entire lifecycle so that they do not pose unreasonable risks.In support of such testing, developers should seek to enable traceability, in relation to datasets, processes, and decisions made during system development.These measures should be documented and supported by regularly updated technical documentation.","passage: This testing should take place in secure environments and be performed at several checkpoints throughout the AI lifecycle in particular before deployment and placement on the market to identify risks and vulnerabilities, and to inform action to address the identified AI risks to security, safety and societal and other risks, whether accidental or intentional.In designing and implementing testing measures, organizations commit to devote attention to the following risks as appropriate:","passage: * Chemical, biological, radiological, and nuclear risks, such as the ways in which advanced AI systems can lower barriers to entry, including for non-state actors, for weapons development, design acquisition, or use.","passage: + Offensive cyber capabilities, such as the ways in which systems can enable vulnerability discovery, exploitation, or operational use, bearing in mind that such capabilities could also have useful defensive applications and might be appropriate to include in a system.","passage: + Risks to health and/or Safety, including the effects of system interaction and tool use, including for example the capacity to control physical systems and interfere with critical infrastructure.","passage: + Risks from models of making copies of themselves or \u201cself-replicating\u201d or training other models.","passage: + Societal risks, as well as risks to individuals and communities such as the ways in which advanced AI systems or models can give rise to harmful bias and discrimination or lead to violation of applicable legal frameworks, including on privacy and data protection.","passage: + Threats to democratic values and human rights, including the facilitation of disinformation or harming privacy.","passage: + Risk that a particular event could lead to a chain reaction with considerable negative effects that could affect up to an entire city, an entire domain activity or an entire community.","passage: Organizations commit to work in collaboration with relevant actors across sectors, to assess and adopt mitigation measures to address these risks, in particular systemic risks.","passage: Organizations making these commitments should also endeavor to advance research and investment on the security, safety, bias and disinformation, fairness, explainability and interpretability, and transparency of advanced AI systems and on increasing robustness and trustworthiness of advanced AI systems against misuse.","passage: **2 Identify and mitigate vulnerabilities, and, where appropriate, incidents and patterns of misuse, after deployment including placement on the market.**","passage: Organizations should use, as and when appropriate commensurate to the level of risk, AI systems as intended and monitor for vulnerabilities, incidents, emerging risks and misuse after deployment, and take appropriate action to address these.Organizations are encouraged to consider, for example, facilitating third-party and user discovery and reporting of issues and vulnerabilities after deployment such as through bounty systems, contests, or prizes to incentivize the responsible disclosure of weaknesses.Organizations are further encouraged to maintain appropriate documentation of reported incidents and to mitigate the identified risks and vulnerabilities, in collaboration with other stakeholders.Mechanisms to report vulnerabilities, where appropriate, should be accessible to a diverse set of stakeholders.","passage: **3 Publicly report advanced AI systems\u2019 capabilities, limitations and domains of appropriate and inappropriate use, to support ensuring sufficient transparency, thereby contributing to increase accountability.**","passage: This should include publishing transparency reports containing meaningful information for all new significant releases of advanced AI systems.","passage: These reports, instruction for use and relevant technical documentation, as appropriate as, should be kept up-to-date and should include, for example;","passage: + Details of the evaluations conducted for potential safety, security, and societal risks, as well as risks to human rights,","passage: + Capacities of a model/system and significant limitations in performance that have implications for the domains of appropriate use,","passage: + Discussion and assessment of the model\u2019s or system\u2019s effects and risks to safety and society such as harmful bias, discrimination, threats to protection of privacy or personal data, and effects on fairness, and","passage: + The results of red-teaming conducted to evaluate the model\u2019s/system\u2019s fitness for moving beyond the development stage.","passage: Organizations should make the information in the transparency reports sufficiently clear and understandable to enable deployers and users as appropriate and relevant to interpret the model/system\u2019s output and to enable users to use it appropriately; and that transparency reporting should be supported and informed by robust documentation processes such as technical documentation and instructions for use.","passage: **4 Work towards responsible information sharing and reporting of incidents among organizations developing advanced AI systems including with industry, governments, civil society, and academia**","passage: This includes responsibly sharing information, as appropriate, including, but not limited to evaluation reports, information on security and safety risks, dangerous intended or unintended capabilities, and attempts by AI actors to circumvent safeguards across the AI lifecycle.","passage: Organizations should establish or join mechanisms to develop, advance, and adopt, where appropriate, shared standards, tools, mechanisms, and best practices for ensuring the safety, security, and trustworthiness of advanced AI systems.","passage: This should also include ensuring appropriate and relevant documentation and transparency across the AI lifecycle in particular for advanced AI systems that cause significant risks to safety and society.","passage: Organizations should collaborate with other organizations across the AI lifecycle to share and report relevant information to the public with a view to advancing safety, security and trustworthiness of advanced AI systems.Organizations should also collaborate and share the aforementioned information with relevant public authorities, as appropriate.","passage: Such reporting should safeguard intellectual property rights.","passage: **5 Develop, implement and disclose AI governance and risk management policies, grounded in a risk-based approach \u2013 including privacy policies, and mitigation measures.**","passage: Organizations should put in place appropriate organizational mechanisms to develop, disclose and implement risk management and governance policies, including for example accountability and governance processes to identify, assess, prevent, and address risks, where feasible throughout the AI lifecycle.","passage: This includes disclosing where appropriate privacy policies, including for personal data, user prompts and advanced AI system outputs.Organizations are expected to establish and disclose their AI governance policies and organizational mechanisms to implement these policies in accordance with a risk based approach.This should include accountability and governance processes to evaluate and mitigate risks, where feasible throughout the AI lifecycle.","passage: The risk management policies should be developed in accordance with a risk based approach and apply a risk management framework across the AI lifecycle as appropriate and relevant, to address the range of risks associated with AI systems, and policies should also be regularly updated.","passage: Organizations should establish policies, procedures, and training to ensure that staff are familiar with their duties and the organization\u2019s risk management practices","passage: **6 Invest in and implement robust security controls, including physical security, cybersecurity and insider threat safeguards across the AI lifecycle.**","passage: These may include securing model weights and, algorithms, servers, and datasets, such as through operational security measures for information security and appropriate cyber/physical access controls.","passage: This also includes performing an assessment of cybersecurity risks and implementing cybersecurity policies and adequate technical and institutional solutions to ensure that the cybersecurity of advanced AI systems is appropriate to the relevant circumstances and the risks involved.Organizations should also have in place measures to require storing and working with the model weights of advanced AI systems in an appropriately secure environment with limited access to reduce both the risk of unsanctioned release and the risk of unauthorized access.This includes a commitment to have in place a vulnerability management process and to regularly review security measures to ensure they are maintained to a high standard and remain suitable to address risks.","passage: This further includes establishing a robust insider threat detection program consistent with protections provided for their most valuable intellectual property and trade secrets, for example, by limiting access to proprietary and unreleased model weights.","passage: **7 Develop and deploy reliable content authentication and provenance mechanisms, where technically feasible, such as watermarking or other techniques to enable users to identify AI-generated content**","passage: This includes, where appropriate and technically feasible, content authentication and provenance mechanisms for content created with an organization\u2019s advanced AI system.The provenance data should include an identifier of the service or model that created the content, but need not include user information.Organizations should also endeavor to develop tools or APIs to allow users to determine if particular content was created with their advanced AI system, such as via watermarks.Organizations should collaborate and invest in research, as appropriate, to advance the state of the field.","passage: Organizations are further encouraged to implement other mechanisms such as labeling or disclaimers to enable users, where possible and appropriate, to know when they are interacting with an AI system.","passage: **8 Prioritize research to mitigate societal, safety and security risks and prioritize investment in effective mitigation measures.**","passage: This includes conducting, collaborating on and investing in research that supports the advancement of AI safety, security, and trust, and addressing key risks, as well as investing in developing appropriate mitigation tools.","passage: Organizations commit to conducting, collaborating on and investing in research that supports the advancement of AI safety, security, trustworthiness and addressing key risks, such as prioritizing research on upholding democratic values, respecting human rights, protecting children and vulnerable groups, safeguarding intellectual property rights and privacy, and avoiding harmful bias, mis- and disinformation, and information manipulation.Organizations also commit to invest in developing appropriate mitigation tools, and work to proactively manage the risks of advanced AI systems, including environmental and climate impacts, so that their benefits can be realized.","passage: Organizations are encouraged to share research and best practices on risk mitigation.","passage: **9 Prioritize the development of advanced AI systems to address the world\u2019s greatest challenges, notably but not limited to the climate crisis, global health and education**","passage: These efforts are undertaken in support of progress on the United Nations Sustainable Development Goals, and to encourage AI development for global benefit.","passage: Organizations should prioritize responsible stewardship of trustworthy and human-centric AI and also support digital literacy initiatives that promote the education and training of the public, including students and workers, to enable them to benefit from the use of advanced AI systems, and to help individuals and communities better understand the nature, capabilities, limitations, and impact of these technologies.Organizations should work with civil society and community groups to identify priority challenges and develop innovative solutions to address the world\u2019s greatest challenges.","passage: **10 Advance the development of and, where appropriate, adoption of international technical standards**","passage: Organizations are encouraged to contribute to the development and, where appropriate, use of international technical standards and best practices, including for watermarking, and working with Standards Development Organizations (SDOs), also when developing organizations\u2019 testing methodologies, content authentication and provenance mechanisms, cybersecurity policies, public reporting, and other measures.In particular, organizations also are encouraged to work to develop interoperable international technical standards and frameworks to help users distinguish content generated by AI from non-AI generated content.","passage: **11 Implement appropriate data input measures and protections for personal data and intellectual property**","passage: Organizations are encouraged to take appropriate measures to manage data quality, including training data and data collection, to mitigate against harmful biases.","passage: Appropriate measures could include transparency, privacy-preserving training techniques, and/or testing and fine-tuning to ensure that systems do not divulge confidential or sensitive data.","passage: Organizations are encouraged to implement appropriate safeguards, to respect rights related to privacy and intellectual property, including copyright-protected content.","passage: Organizations should also comply with applicable legal frameworks.","passage: # The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023","passage: Artificial Intelligence (AI) presents enormous global opportunities: it has the potential to transform and enhance human wellbeing, peace and prosperity.To realise this, we affirm that, for the good of all,\u00a0AI\u00a0should be designed, developed, deployed, and used, in a manner that is safe, in such a way as to be human-centric, trustworthy and responsible.We welcome the international community\u2019s efforts so far to cooperate on\u00a0AI\u00a0to promote inclusive economic growth, sustainable development and innovation, to protect human rights and fundamental freedoms, and to foster public trust and confidence in\u00a0AI\u00a0systems to fully realise their potential.","passage: AI\u00a0systems are already deployed across many domains of daily life including housing, employment, transport, education, health, accessibility, and justice, and their use is likely to increase.We recognise that this is therefore a unique moment to act and affirm the need for the safe development of\u00a0AI\u00a0and for the transformative opportunities of\u00a0AIto be used for good and for all, in an inclusive manner in our countries and globally.This includes for public services such as health and education, food security, in science, clean energy, biodiversity, and climate, to realise the enjoyment of human rights, and to strengthen efforts towards the achievement of the United Nations Sustainable Development Goals.","passage: Alongside these opportunities,\u00a0AI\u00a0also poses significant risks, including in those domains of daily life.To that end, we welcome relevant international efforts to examine and address the potential impact of\u00a0AI\u00a0systems in existing fora and other relevant initiatives, and the recognition that the protection of human rights, transparency and explainability, fairness, accountability, regulation, safety, appropriate human oversight, ethics, bias mitigation, privacy and data protection needs to be addressed.We also note the potential for unforeseen risks stemming from the capability to manipulate content or generate deceptive content.All of these issues are critically important and we affirm the necessity and urgency of addressing them.","passage: Particular safety risks arise at the \u2018frontier\u2019 of\u00a0AI, understood as being those highly capable general-purpose\u00a0AI\u00a0models, including foundation models, that could perform a wide variety of tasks - as well as relevant specific narrow\u00a0AI\u00a0that could exhibit capabilities that cause harm - which match or exceed the capabilities present in today\u2019s most advanced models.Substantial risks may arise from potential intentional misuse or unintended issues of control relating to alignment with human intent.These issues are in part because those capabilities are not fully understood and are therefore hard to predict.We are especially concerned by such risks in domains such as cybersecurity and biotechnology, as well as where frontier\u00a0AI\u00a0systems may amplify risks such as disinformation.There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these\u00a0AI\u00a0models.Given the rapid and uncertain rate of change of\u00a0AI, and in the context of the acceleration of investment in technology, we affirm that deepening our understanding of these potential risks and of actions to address them is especially urgent.","passage: Many risks arising from\u00a0AI\u00a0are inherently international in nature, and so are best addressed through international cooperation.We resolve to work together in an inclusive manner to ensure human-centric, trustworthy and responsible\u00a0AI\u00a0that is safe, and supports the good of all through existing international fora and other relevant initiatives, to promote cooperation to address the broad range of risks posed by\u00a0AI.In doing so,\u00a0we recognise\u00a0that countries should consider the importance of a pro-innovation and proportionate governance\u00a0and regulatory\u00a0approach that maximises the benefits and takes into account the risks associated with\u00a0AI.\u00a0This could include making, where appropriate, classifications and categorisations of risk based on national circumstances and applicable legal frameworks.\u00a0We also note the relevance of cooperation, where appropriate, on approaches such as common principles and\u00a0codes\u00a0of conduct.With regard to the specific risks most likely found in relation to frontier\u00a0AI, we resolve to intensify and sustain our cooperation, and broaden it with further countries, to identify, understand and as appropriate act, through existing international fora and other relevant initiatives, including future international\u00a0AI\u00a0Safety Summits.","passage: All actors have a role to play in ensuring the safety of\u00a0AI: nations, international fora and other initiatives, companies, civil society and academia will need to work together.Noting the importance of inclusive\u00a0AI\u00a0and bridging the digital divide, we reaffirm that international collaboration should endeavour to engage and involve a broad range of partners as appropriate, and welcome development-orientated approaches and policies that could help developing countries strengthen\u00a0AI\u00a0capacity building and leverage the enabling role of\u00a0AI\u00a0to support sustainable growth and address the development gap.","passage: We affirm that, whilst safety must be considered across the\u00a0AI\u00a0lifecycle, actors developing frontier\u00a0AI\u00a0capabilities, in particular those\u00a0AI\u00a0systems which are unusually powerful and potentially harmful, have a particularly strong responsibility for ensuring the safety of these\u00a0AI\u00a0systems, including through systems for safety testing, through evaluations, and by other appropriate measures.We encourage all relevant actors to provide context-appropriate transparency and accountability on their plans to measure, monitor and mitigate potentially harmful capabilities and the associated effects that may emerge, in particular to prevent misuse and issues of control, and the amplification of other risks.","passage: In the context of our cooperation, and to inform action at the national and international levels, our agenda for addressing frontier\u00a0AI\u00a0risk will focus on:","passage: - identifying\u00a0AI\u00a0safety risks of shared concern, building a shared scientific and evidence-based understanding of these risks, and sustaining that understanding as capabilities continue to increase, in the context of a wider global approach to understanding the impact of\u00a0AI\u00a0in our societies.","passage: - building respective risk-based policies across our countries to ensure safety in light of such risks, collaborating as appropriate while recognising our approaches may differ based on national circumstances and applicable legal frameworks.This includes, alongside increased transparency by private actors developing frontier\u00a0AIcapabilities, appropriate evaluation metrics, tools for safety testing, and developing relevant public sector capability and scientific research.","passage: In furtherance of this agenda, we resolve to support an internationally inclusive network of scientific research on frontier\u00a0AI\u00a0safety that encompasses and complements existing and new multilateral, plurilateral and bilateral collaboration, including through existing international fora and other relevant initiatives, to facilitate the provision of the best science available for policy making and the public good.","passage: In recognition of the transformative positive potential of\u00a0AI, and as part of ensuring wider international cooperation on\u00a0AI, we resolve to sustain an inclusive global dialogue that engages existing international fora and other relevant initiatives and contributes in an open manner to broader international discussions, and to continue research on frontier\u00a0AI\u00a0safety to ensure that the benefits of the technology can be harnessed responsibly for good and for all.We look forward to meeting again in 2024.","passage: The countries represented were:","passage: - Australia","passage: - Brazil","passage: - Canada","passage: - Chile","passage: - China","passage: - European Union","passage: - France","passage: - Germany","passage: - India","passage: - Indonesia","passage: - Ireland","passage: - Israel","passage: - Italy","passage: - Japan","passage: - Kenya","passage: - Kingdom of Saudi Arabia","passage: - Netherlands","passage: - Nigeria","passage: - The Philippines","passage: - Republic of Korea","passage: - Rwanda","passage: - Singapore","passage: - Spain","passage: - Switzerland","passage: - T\u00fcrkiye","passage: - Ukraine","passage: - United Arab Emirates","passage: - United Kingdom of Great Britain and Northern Ireland","passage: - United States of America","passage: References to \u2018governments\u2019 and \u2018countries\u2019 include international organisations acting in accordance with their legislative or executive competences."],"shape":[742],"dtype":"object","order":"little"}],["alpha",{"type":"ndarray","array":{"type":"bytes","data":"AQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAA=="},"shape":[742],"dtype":"int32","order":"little"}]]}}},"view":{"type":"object","name":"CDSView","id":"p1312","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p1313"}}},"glyph":{"type":"object","name":"Circle","id":"p1308","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":5},"line_color":{"type":"field","field":"color"},"line_alpha":{"type":"field","field":"alpha"},"fill_color":{"type":"field","field":"color"},"fill_alpha":{"type":"field","field":"alpha"},"hatch_color":{"type":"field","field":"color"},"hatch_alpha":{"type":"field","field":"alpha"}}},"nonselection_glyph":{"type":"object","name":"Circle","id":"p1309","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":5},"line_color":{"type":"field","field":"color"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"field","field":"color"},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"field","field":"color"},"hatch_alpha":{"type":"value","value":0.1}}},"muted_glyph":{"type":"object","name":"Circle","id":"p1310","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":5},"line_color":{"type":"field","field":"color"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"field","field":"color"},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"field","field":"color"},"hatch_alpha":{"type":"value","value":0.2}}}}}],"toolbar":{"type":"object","name":"Toolbar","id":"p1284","attributes":{"tools":[{"type":"object","name":"PanTool","id":"p1297"},{"type":"object","name":"WheelZoomTool","id":"p1298","attributes":{"renderers":"auto"}},{"type":"object","name":"BoxZoomTool","id":"p1299","attributes":{"overlay":{"type":"object","name":"BoxAnnotation","id":"p1300","attributes":{"syncable":false,"level":"overlay","visible":false,"left_units":"canvas","right_units":"canvas","top_units":"canvas","bottom_units":"canvas","line_color":"black","line_alpha":1.0,"line_width":2,"line_dash":[4,4],"fill_color":"lightgrey","fill_alpha":0.5}}}},{"type":"object","name":"SaveTool","id":"p1301"},{"type":"object","name":"ResetTool","id":"p1302"},{"type":"object","name":"HelpTool","id":"p1303"},{"type":"object","name":"HoverTool","id":"p1304","attributes":{"renderers":"auto","tooltips":[["text","@{text}"]]}}]}},"left":[{"type":"object","name":"LinearAxis","id":"p1292","attributes":{"visible":false,"ticker":{"type":"object","name":"BasicTicker","id":"p1293","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1294"},"major_label_policy":{"type":"object","name":"AllLabels","id":"p1295"}}}],"below":[{"type":"object","name":"LinearAxis","id":"p1287","attributes":{"visible":false,"ticker":{"type":"object","name":"BasicTicker","id":"p1288","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1289"},"major_label_policy":{"type":"object","name":"AllLabels","id":"p1290"}}}],"center":[{"type":"object","name":"Grid","id":"p1291","attributes":{"visible":false,"axis":{"id":"p1287"}}},{"type":"object","name":"Grid","id":"p1296","attributes":{"visible":false,"dimension":1,"axis":{"id":"p1292"}}}],"background_fill_color":"white"}}],"defs":[{"type":"model","name":"ReactiveHTML1"},{"type":"model","name":"FlexBox1","properties":[{"name":"align_content","kind":"Any","default":"flex-start"},{"name":"align_items","kind":"Any","default":"flex-start"},{"name":"flex_direction","kind":"Any","default":"row"},{"name":"flex_wrap","kind":"Any","default":"wrap"},{"name":"justify_content","kind":"Any","default":"flex-start"}]},{"type":"model","name":"FloatPanel1","properties":[{"name":"config","kind":"Any","default":{"type":"map"}},{"name":"contained","kind":"Any","default":true},{"name":"position","kind":"Any","default":"right-top"},{"name":"offsetx","kind":"Any","default":null},{"name":"offsety","kind":"Any","default":null},{"name":"theme","kind":"Any","default":"primary"},{"name":"status","kind":"Any","default":"normalized"}]},{"type":"model","name":"GridStack1","properties":[{"name":"mode","kind":"Any","default":"warn"},{"name":"ncols","kind":"Any","default":null},{"name":"nrows","kind":"Any","default":null},{"name":"allow_resize","kind":"Any","default":true},{"name":"allow_drag","kind":"Any","default":true},{"name":"state","kind":"Any","default":[]}]},{"type":"model","name":"drag1","properties":[{"name":"slider_width","kind":"Any","default":5},{"name":"slider_color","kind":"Any","default":"black"},{"name":"value","kind":"Any","default":50}]},{"type":"model","name":"click1","properties":[{"name":"terminal_output","kind":"Any","default":""},{"name":"debug_name","kind":"Any","default":""},{"name":"clears","kind":"Any","default":0}]},{"type":"model","name":"toggle_value1","properties":[{"name":"active_icons","kind":"Any","default":{"type":"map"}},{"name":"options","kind":"Any","default":{"type":"map","entries":[["favorite","heart"]]}},{"name":"value","kind":"Any","default":[]},{"name":"_reactions","kind":"Any","default":[]},{"name":"_base_url","kind":"Any","default":"https://tabler-icons.io/static/tabler-icons/icons/"}]},{"type":"model","name":"copy_to_clipboard1","properties":[{"name":"value","kind":"Any","default":null},{"name":"fill","kind":"Any","default":"none"}]},{"type":"model","name":"FastWrapper1","properties":[{"name":"object","kind":"Any","default":null},{"name":"style","kind":"Any","default":null}]},{"type":"model","name":"NotificationAreaBase1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0}]},{"type":"model","name":"NotificationArea1","properties":[{"name":"js_events","kind":"Any","default":{"type":"map"}},{"name":"notifications","kind":"Any","default":[]},{"name":"position","kind":"Any","default":"bottom-right"},{"name":"_clear","kind":"Any","default":0},{"name":"types","kind":"Any","default":[{"type":"map","entries":[["type","warning"],["background","#ffc107"],["icon",{"type":"map","entries":[["className","fas fa-exclamation-triangle"],["tagName","i"],["color","white"]]}]]},{"type":"map","entries":[["type","info"],["background","#007bff"],["icon",{"type":"map","entries":[["className","fas fa-info-circle"],["tagName","i"],["color","white"]]}]]}]}]},{"type":"model","name":"Notification","properties":[{"name":"background","kind":"Any","default":null},{"name":"duration","kind":"Any","default":3000},{"name":"icon","kind":"Any","default":null},{"name":"message","kind":"Any","default":""},{"name":"notification_type","kind":"Any","default":null},{"name":"_destroyed","kind":"Any","default":false}]},{"type":"model","name":"TemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"BootstrapTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]},{"type":"model","name":"MaterialTemplateActions1","properties":[{"name":"open_modal","kind":"Any","default":0},{"name":"close_modal","kind":"Any","default":0}]}]}}
    </script>
    <script type="text/javascript">
      (function() {
        const fn = function() {
          Bokeh.safely(function() {
            (function(root) {
              function embed_document(root) {
              const docs_json = document.getElementById('p1322').textContent;
              const render_items = [{"docid":"a482eea9-0ced-4ca4-9567-4517c36bf689","roots":{"p1276":"e9ebadd3-045d-4e2c-9b5e-a91173f9af64"},"root_ids":["p1276"]}];
              root.Bokeh.embed.embed_items(docs_json, render_items);
              }
              if (root.Bokeh !== undefined) {
                embed_document(root);
              } else {
                let attempts = 0;
                const timer = setInterval(function(root) {
                  if (root.Bokeh !== undefined) {
                    clearInterval(timer);
                    embed_document(root);
                  } else {
                    attempts++;
                    if (attempts > 100) {
                      clearInterval(timer);
                      console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                    }
                  }
                }, 10, root)
              }
            })(window);
          });
        };
        if (document.readyState != "loading") fn();
        else document.addEventListener("DOMContentLoaded", fn);
      })();
    </script>
  </body>
</html>